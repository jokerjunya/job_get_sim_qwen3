from agents.base_agent import BaseAgent
import random
import json
import re

class SimulatedSeeker(BaseAgent):
    def __init__(self, name: str = "SimulatedSeeker", description: str = "æ±‚è·è€…ã®äººæ ¼ãƒ»æ„Ÿæƒ…ã‚’å†ç¾ã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"):
        super().__init__(name, description)
        with open("prompts/seeker_motivation.txt", encoding="utf-8") as f:
            self.motivation_prompt_template = f.read().strip()
        with open("prompts/seeker_answer_interview.txt", encoding="utf-8") as f:
            self.answer_interview_prompt_template = f.read().strip()

    async def generate_motivation(self, job: dict) -> str:
        # å¿—æœ›å‹•æ©Ÿã‚’Qwen3ã§ç”Ÿæˆ
        prompt = self.motivation_prompt_template.format(job_title=job['title'], company=job['company'])
        return await self.llm.generate_content_async(prompt, agent_name="SimulatedSeekerï¼ˆæ±‚è·è€…ï¼‰")

    async def answer_interview(self, question: str, seeker_profile: dict = None) -> str:
        # é¢æ¥è³ªå•ã¸ã®å¿œç­”ã‚’Qwen3ã§ç”Ÿæˆ
        # å¿œå‹Ÿè€…æƒ…å ±ã‚’è¦ç´„ã—ã¦åŸ‹ã‚è¾¼ã‚€
        seeker_info = ""
        if seeker_profile:
            name = seeker_profile.get("name", "")
            values = ", ".join(seeker_profile.get("values", []))
            skills = ", ".join(seeker_profile.get("skills", []))
            current_job = seeker_profile.get("current_job", {})
            current_position = current_job.get("role", "")
            current_company = current_job.get("company", "")
            experience = seeker_profile.get("experience", "")
            tags = ", ".join(seeker_profile.get("tags", []))
            
            seeker_info = f"""
ã‚ãªãŸã¯ä»¥ä¸‹ã®ç‰¹å¾´ã‚’æŒã¤æ±‚è·è€…ã§ã™ï¼š
- åå‰: {name}
- ç¾è·: {current_company} {current_position}
- ã‚¹ã‚­ãƒ«: {skills}
- ä¾¡å€¤è¦³: {values}
- çµŒé¨“: {experience}
- ç‰¹å¾´: {tags}

ã‚ãªãŸã®ç‰¹å¾´ãƒ»çµŒæ­´ãƒ»ä¾¡å€¤è¦³ã«åŸºã¥ã„ã¦ã€å…·ä½“çš„ãªã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚„å®Ÿéš›ã®çµŒé¨“ã‚’äº¤ãˆãªãŒã‚‰å›ç­”ã—ã¦ãã ã•ã„ã€‚
"""
            
        prompt = self.answer_interview_prompt_template.format(
            question=question,
            seeker_profile=seeker_info
        )
        return await self.llm.generate_content_async(prompt, agent_name="SimulatedSeekerï¼ˆæ±‚è·è€…ï¼‰")

    async def decide_offer(self, offer: dict, seeker_profile: dict = None, job: dict = None, interview_evaluations: list = None) -> dict:
        """
        ã‚ªãƒ•ã‚¡ãƒ¼å—è«¾åˆ¤æ–­ã‚’å¯¾è©±å½¢å¼ã§è¡Œã†ã€‚
        ã€Œå•ã„ Ã— é–“ Ã— ä¾‹ã€ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ä½¿ã£ã¦ã€ç´å¾—æ„Ÿã®ã‚ã‚‹æ„æ€æ±ºå®šãƒ—ãƒ­ã‚»ã‚¹ã‚’è¡¨ç¾ã™ã‚‹ã€‚
        
        Args:
            offer: ã‚ªãƒ•ã‚¡ãƒ¼å†…å®¹ã®è¾æ›¸ï¼ˆå¹´åã€å…¥ç¤¾æ—¥ãªã©ï¼‰
            seeker_profile: æ±‚è·è€…ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«
            job: æ±‚äººæƒ…å ±
            interview_evaluations: é¢æ¥è©•ä¾¡ã®ãƒªã‚¹ãƒˆ
            
        Returns:
            dict: æ±ºæ–­çµæœã¨ä¼šè©±å†…å®¹
        """
        with open("prompts/seeker_offer_conversation.txt", encoding="utf-8") as f:
            prompt_template = f.read().strip()
        
        # è¿·ã„ã‚¹ã‚³ã‚¢ã®è¨ˆç®—ï¼ˆã‚ˆã‚Šç¾å®Ÿçš„ã§å¤šè§’çš„ã«ï¼‰
        hesitation_score = 0
        hesitation_factors = []  # è¿·ã„ã®è¦å› ã‚’è¨˜éŒ²
        
        if seeker_profile:
            # 1. å¹´åé¢ã§ã®è€ƒæ…®ï¼ˆã‚ˆã‚Šç´°ã‹ãï¼‰
            hope_salary = seeker_profile.get("hope_conditions", {}).get("min_salary", 0)
            offer_salary = offer.get("å¹´å", 0)
            if hope_salary > 0 and offer_salary > 0:
                salary_gap = (hope_salary - offer_salary) / hope_salary
                if salary_gap > 0.2:  # å¸Œæœ›ã‚ˆã‚Š20%ä»¥ä¸Šä½ã„
                    hesitation_score += 3
                    hesitation_factors.append("å¹´åãŒæœŸå¾…ã‚ˆã‚Šå¤§å¹…ã«ä½ã„")
                elif salary_gap > 0.1:  # å¸Œæœ›ã‚ˆã‚Š10%ä»¥ä¸Šä½ã„
                    hesitation_score += 2
                    hesitation_factors.append("å¹´åãŒæœŸå¾…ã‚ˆã‚Šä½ã„")
                elif salary_gap > 0:  # å°‘ã—ã§ã‚‚ä½ã„
                    hesitation_score += 1
                    hesitation_factors.append("å¹´åãŒæœŸå¾…ã‚’ã‚ãšã‹ã«ä¸‹å›ã‚‹")
                elif salary_gap <= -0.2:  # å¸Œæœ›ã‚ˆã‚Š20%ä»¥ä¸Šé«˜ã„ï¼ˆé€†ã«ä¸å®‰ã«ãªã‚‹ï¼‰
                    hesitation_score += 1
                    hesitation_factors.append("å¹´åãŒé«˜ã™ãã¦è²¬ä»»ã¸ã®ä¸å®‰")
            
            # 2. ã‚­ãƒ£ãƒªã‚¢æˆé•·ã¸ã®ä¸å®‰ï¼ˆç¾è·æ­´ã‹ã‚‰æ¨æ¸¬ï¼‰
            current_job = seeker_profile.get("current_job", {})
            current_period = current_job.get("period", "")
            if "ç¾åœ¨" in current_period or "2024" in current_period:
                # ç¾è·æ­´ãŒçŸ­ã„ï¼ˆ1-2å¹´ï¼‰å ´åˆã¯è»¢è·ã¸ã®ä¸å®‰
                hesitation_score += 1
                hesitation_factors.append("ç¾è·æ­´ãŒçŸ­ãè»¢è·ã¸ã®ä¸å®‰")
            
            # 3. ãƒ¯ãƒ¼ã‚¯ãƒ©ã‚¤ãƒ•ãƒãƒ©ãƒ³ã‚¹ã¸ã®æ‡¸å¿µ
            if "å®¶æ—" in seeker_profile.get("context", "") or "å­ã©ã‚‚" in seeker_profile.get("context", ""):
                hesitation_score += 1
                hesitation_factors.append("å®¶æ—ã¨ã®æ™‚é–“ã¸ã®é…æ…®")
            
            # 4. ä¾¡å€¤è¦³ã®ä¸€è‡´åº¦ï¼ˆé€†ã«ä¸€è‡´ã—ã™ãã¦ã‚‚ä¸å®‰ã«ãªã‚‹è¦å› ï¼‰
            if job and "culture_keywords" in job:
                seeker_values = seeker_profile.get("values", [])
                job_culture = job["culture_keywords"]
                values_match = sum(1 for v in seeker_values if v in job_culture)
                if values_match == 0:
                    hesitation_score += 2
                    hesitation_factors.append("ä¾¡å€¤è¦³ã®ä¸ä¸€è‡´")
                elif values_match == len(seeker_values):  # 100%ä¸€è‡´ã¯é€†ã«ä¸å®‰
                    hesitation_score += 0.5
                    hesitation_factors.append("ä¾¡å€¤è¦³ãŒä¸€è‡´ã—ã™ãã‚‹ã“ã¨ã¸ã®è‹¥å¹²ã®ä¸å®‰")
                
            # 5. é¢æ¥ã§ã®å°è±¡ã‚„ä¸å®‰è¦ç´ 
            if interview_evaluations:
                for eval in interview_evaluations:
                    if "èª²é¡Œ" in eval or "æ”¹å–„" in eval:
                        hesitation_score += 0.5
                        hesitation_factors.append("é¢æ¥ã§æŒ‡æ‘˜ã•ã‚ŒãŸèª²é¡Œã¸ã®ä¸å®‰")
            
            # 6. æ–°ã—ã„ç’°å¢ƒã¸ã®é©å¿œä¸å®‰ï¼ˆè»¢è·å…±é€šã®ä¸å®‰ï¼‰
            hesitation_score += 1
            hesitation_factors.append("æ–°ã—ã„ç’°å¢ƒã¸ã®é©å¿œã¸ã®ä¸å®‰")
            
            # 7. ç¾è·ã¸ã®æ„›ç€ãƒ»ç¾©ç†ï¼ˆå¿…ãšç™ºç”Ÿã™ã‚‹è¦å› ï¼‰
            hesitation_score += 1
            hesitation_factors.append("ç¾è·ã¸ã®æ„›ç€ã‚„åŒåƒšãƒ»ä¼šç¤¾ã¸ã®ç¾©ç†")
        
        # è¿·ã„ã®åº¦åˆã„ã«å¿œã˜ãŸã‚¿ãƒ¼ãƒ³æ•°ã®æ±ºå®šï¼ˆèª¿æ•´ï¼‰
        if hesitation_score >= 4:
            turns = "many"  # å¤šæ•°ã®ã‚¿ãƒ¼ãƒ³ï¼ˆ5å›ä»¥ä¸Šï¼‰
        elif hesitation_score >= 2:
            turns = "some"  # é©åº¦ãªã‚¿ãƒ¼ãƒ³ï¼ˆ3-4å›ï¼‰
        else:
            turns = "few"   # å°‘æ•°ã®ã‚¿ãƒ¼ãƒ³ï¼ˆ1-2å›ï¼‰
        
        prompt = prompt_template.format(
            offer=json.dumps(offer, ensure_ascii=False),
            seeker_profile=json.dumps(seeker_profile, ensure_ascii=False) if seeker_profile else "{}",
            job=json.dumps(job, ensure_ascii=False) if job else "{}",
            interview_evaluations=json.dumps(interview_evaluations, ensure_ascii=False) if interview_evaluations else "[]",
            hesitation_score=hesitation_score,
            turns=turns
        )
        
        conversation = await self.llm.generate_content_async(prompt, agent_name="SimulatedSeekerï¼ˆæ±‚è·è€…ï¼‰")
        
        # ã‚ˆã‚Šç²¾å¯†ãªæ±ºæ–­æŠ½å‡ºãƒ­ã‚¸ãƒƒã‚¯
        conversation_lines = conversation.strip().split('\n')
        final_decision = None
        decision_confidence = 0
        
        # æ˜ç¤ºçš„ãªæ±ºæ–­è¡¨ç¾ã‚’æ¢ã™ï¼ˆå„ªå…ˆåº¦é«˜ï¼‰
        accept_patterns = [
            r'å—è«¾ã—ã¾ã™', r'å—ã‘å…¥ã‚Œã¾ã™', r'æŒ‘æˆ¦.*ã—ã¾ã™', r'ãŠå—ã‘ã—ã¾ã™',
            r'å—è«¾.*æ±ºã‚ã¾ã—ãŸ', r'å—ã‘ã‚‹ã“ã¨.*æ±ºã‚ã¾ã—ãŸ', r'ã‚„ã£ã¦ã¿ã¾ã™'
        ]
        reject_patterns = [
            r'è¾é€€ã—ã¾ã™', r'è¦‹é€.*ã—ã¾ã™', r'ãŠæ–­ã‚Šã—ã¾ã™', r'è¾é€€.*æ±ºã‚ã¾ã—ãŸ',
            r'è¦‹é€.*æ±ºã‚ã¾ã—ãŸ', r'ä»Šå›.*è¦‹é€', r'æ®‹ã‚‹.*æ±ºã‚ã¾ã—ãŸ'
        ]
        
        # æœ€å¾Œã®5è¡Œã‚’é‡ç‚¹çš„ã«ãƒã‚§ãƒƒã‚¯
        for line in reversed(conversation_lines[-5:]):
            line_lower = line.lower().strip()
            
            # å—è«¾ã®æ˜ç¤ºçš„è¡¨ç¾
            for pattern in accept_patterns:
                if re.search(pattern, line):
                    final_decision = True
                    decision_confidence = 3
                    break
            
            # è¾é€€ã®æ˜ç¤ºçš„è¡¨ç¾  
            for pattern in reject_patterns:
                if re.search(pattern, line):
                    final_decision = False
                    decision_confidence = 3
                    break
                    
            if decision_confidence == 3:  # æ˜ç¢ºãªæ±ºæ–­ãŒè¦‹ã¤ã‹ã£ãŸ
                break
        
        # æ˜ç¤ºçš„ãªè¡¨ç¾ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€å…¨ä½“çš„ãªãƒˆãƒ¼ãƒ³ã‹ã‚‰åˆ¤æ–­
        if decision_confidence < 3:
            conversation_text = conversation.lower()
            accept_words = conversation_text.count('å—è«¾') + conversation_text.count('å—ã‘å…¥ã‚Œ') + conversation_text.count('æŒ‘æˆ¦')
            reject_words = conversation_text.count('è¾é€€') + conversation_text.count('è¦‹é€') + conversation_text.count('æ®‹ã‚‹')
            
            if accept_words > reject_words:
                final_decision = True
                decision_confidence = 1
            elif reject_words > accept_words:
                final_decision = False
                decision_confidence = 1
            else:
                # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯å—è«¾ï¼ˆè¿·ã„ãŒå°‘ãªã„å ´åˆï¼‰
                final_decision = True if hesitation_score < 3 else False
                decision_confidence = 0
        
        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã®å‡ºåŠ›
        decision_text = "å—è«¾" if final_decision else "è¾é€€"
        confidence_text = ["æ¨æ¸¬", "å‚¾å‘åˆ¤æ–­", "æ˜ç¢ºãªè¡¨ç¾", "æ˜ç¤ºçš„æ±ºæ–­"][min(decision_confidence, 3)]
        print(f"æ±ºæ–­æŠ½å‡º: {decision_text} (ä¿¡é ¼åº¦: {confidence_text}, ã‚¹ã‚³ã‚¢: {hesitation_score})")
        
        return {
            "decision": final_decision,
            "conversation": conversation.strip(),
            "hesitation_score": hesitation_score,
            "hesitation_factors": hesitation_factors,
            "decision_confidence": decision_confidence
        }

    async def self_introduction(self) -> str:
        with open("prompts/seeker_self_introduction.txt", encoding="utf-8") as f:
            prompt_template = f.read().strip()
        prompt = prompt_template
        intro = await self.llm.generate_content_async(prompt, agent_name="SimulatedSeekerï¼ˆæ±‚è·è€…ï¼‰")
        return intro.strip()

    async def job_question(self, job_proposal: str) -> str:
        with open("prompts/seeker_job_question.txt", encoding="utf-8") as f:
            prompt_template = f.read().strip()
        prompt = prompt_template.format(job_proposal=job_proposal)
        question = await self.llm.generate_content_async(prompt, agent_name="SimulatedSeekerï¼ˆæ±‚è·è€…ï¼‰")
        return question.strip()

    async def job_final_decision(self, job_proposal: str) -> str:
        with open("prompts/seeker_job_final_decision.txt", encoding="utf-8") as f:
            prompt_template = f.read().strip()
        prompt = prompt_template.format(job_proposal=job_proposal)
        decision = await self.llm.generate_content_async(prompt, agent_name="SimulatedSeekerï¼ˆæ±‚è·è€…ï¼‰")
        return decision.strip()

    async def start_conversation(self, seeker_profile: dict) -> str:
        with open("prompts/seeker_life_topic.txt", encoding="utf-8") as f:
            prompt_template = f.read().strip()
        prompt = prompt_template.format(seeker_profile=seeker_profile)
        conversation = await self.llm.generate_content_async(prompt, agent_name="SimulatedSeekerï¼ˆæ±‚è·è€…ï¼‰")
        return conversation.strip()

    async def reply_in_conversation(self, history: str) -> str:
        with open("prompts/seeker_reply.txt", encoding="utf-8") as f:
            prompt_template = f.read().strip()
        prompt = prompt_template.format(history=history)
        reply = await self.llm.generate_content_async(prompt, agent_name="SimulatedSeekerï¼ˆæ±‚è·è€…ï¼‰")
        return reply.strip()

    async def job_intent(self, job_pitch: str) -> str:
        with open("prompts/seeker_job_intent.txt", encoding="utf-8") as f:
            prompt_template = f.read().strip()
        prompt = prompt_template.format(job_pitch=job_pitch)
        intent = await self.llm.generate_content_async(prompt, agent_name="SimulatedSeekerï¼ˆæ±‚è·è€…ï¼‰")
        return intent.strip()

    async def application_reason(self, seeker_profile: dict, job: dict) -> str:
        with open("prompts/seeker_application_reason.txt", encoding="utf-8") as f:
            prompt_template = f.read().strip()
        
        # seekerãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã®æƒ…å ±ã‚’æ–‡å­—åˆ—åŒ–
        seeker_info = f"æ±‚è·è€…ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«: {json.dumps(seeker_profile, ensure_ascii=False, indent=2)}"
        job_info = f"æ±‚äººæƒ…å ±: {json.dumps(job, ensure_ascii=False, indent=2)}"
        
        prompt = prompt_template.format(
            seeker_profile=seeker_info,
            job=job_info
        )
        return await self.llm.generate_content_async(prompt, agent_name="SimulatedSeekerï¼ˆæ±‚è·è€…ï¼‰")
    
    def notify_interview_scheduled(self, scheduled_slot: dict, interviewer_name: str = None) -> str:
        """
        é¢æ¥æ—¥ç¨‹ãŒæ±ºå®šã—ãŸã“ã¨ã‚’æ±‚è·è€…ã«é€šçŸ¥ã™ã‚‹
        
        Args:
            scheduled_slot: ç¢ºå®šã—ãŸé¢æ¥ã‚¹ãƒ­ãƒƒãƒˆ {"start": "...", "end": "..."}
            interviewer_name: é¢æ¥å®˜å
            
        Returns:
            æ±‚è·è€…ã‹ã‚‰ã®å¿œç­”ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        """
        from .schedule_agent import ScheduleAgent
        
        schedule_agent = ScheduleAgent()
        start_dt = schedule_agent.parse_iso_datetime(scheduled_slot["start"])
        end_dt = schedule_agent.parse_iso_datetime(scheduled_slot["end"])
        
        # æ—¥æœ¬æ™‚é–“ã§ã®è¡¨ç¤º
        start_jst = start_dt.astimezone(schedule_agent.timezone)
        end_jst = end_dt.astimezone(schedule_agent.timezone)
        
        date_str = start_jst.strftime("%Yå¹´%mæœˆ%dæ—¥")
        start_time = start_jst.strftime("%H:%M")
        end_time = end_jst.strftime("%H:%M")
        
        # æ±‚è·è€…ã‹ã‚‰ã®è¿”ç­”ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç”Ÿæˆ
        response_patterns = [
            f"ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ï¼{date_str} {start_time}ã€œ{end_time}ã§æ‰¿çŸ¥ã—ã¾ã—ãŸã€‚",
            f"äº†è§£ã„ãŸã—ã¾ã™ã€‚{date_str} {start_time}ã‹ã‚‰é¢æ¥ã‚’ã‚ˆã‚ã—ããŠé¡˜ã„ã—ã¾ã™ã€‚",
            f"{date_str} {start_time}ã€œã®é¢æ¥ã€äº†æ‰¿ã„ãŸã—ã¾ã™ã€‚å½“æ—¥ã¯ã‚ˆã‚ã—ããŠé¡˜ã„ã„ãŸã—ã¾ã™ã€‚",
            f"é¢æ¥æ—¥ç¨‹ã‚’ã”èª¿æ•´ã„ãŸã ãã€ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚{date_str} {start_time}ã€œã§ãŠå¾…ã¡ã—ã¦ãŠã‚Šã¾ã™ã€‚"
        ]
        
        response = random.choice(response_patterns)
        if interviewer_name:
            response += f"\n{interviewer_name}æ§˜ã«ãŠä¼šã„ã§ãã‚‹ã®ã‚’æ¥½ã—ã¿ã«ã—ã¦ãŠã‚Šã¾ã™ã€‚"
        
        print(f"ğŸ“§ æ±‚è·è€…ã‹ã‚‰ã®è¿”ä¿¡:\n{response}")
        print("=" * 50)
        
        return response 