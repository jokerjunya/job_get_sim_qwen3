import asyncio
import json
import os
import datetime
import re
import shutil
from agents.job_simulation.seeker_agent import SeekerAgent
from agents.job_simulation.employer_agent import EmployerAgent
from agents.job_simulation.simulated_seeker import SimulatedSeeker
from agents.job_simulation.simulated_interviewer import SimulatedInterviewer
from agents.job_simulation.simulated_hr import SimulatedHR
from agents.job_simulation.data_manager import DataManager

async def main():
    now_str = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
    os.makedirs('logs', exist_ok=True)
    log_path = f'logs/simulation_log_{now_str}.jsonl'
    log_md_path = f'logs/simulation_log_{now_str}.md'
    log_html_path = f'logs/simulation_log_{now_str}.html'
    step_counter = 1
    # logã®ãƒªã‚¹ãƒˆï¼ˆå¾Œã§é¢æ¥è©•ä¾¡ã‚’å–å¾—ã™ã‚‹ãŸã‚ã«ä½¿ç”¨ï¼‰
    logs = []
    html_content = []  # HTMLã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ä¿å­˜ã™ã‚‹ãƒªã‚¹ãƒˆ
    current_progress = ""  # ç¾åœ¨ã®é€²æ—çŠ¶æ³
    completed_steps = []  # å®Œäº†ã—ãŸã‚¹ãƒ†ãƒƒãƒ—ãƒªã‚¹ãƒˆ
    is_simulation_completed = False  # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Œäº†ãƒ•ãƒ©ã‚°
    
    # DataManagerã‚’åˆæœŸåŒ–
    data_manager = DataManager()
    
    # ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º
    stats = data_manager.get_stats()
    print("ğŸ“Š ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆæƒ…å ±:")
    print(f"  æ±‚è·è€…æ•°: {stats['seekers_count']}")
    print(f"  æ±‚äººãƒ‘ã‚¿ãƒ¼ãƒ³æ•°: {stats['job_patterns_count']}")
    print(f"  é™çš„æ±‚äººæ•°: {stats['static_jobs_count']}")
    print(f"  æ±‚è·è€…ã‚¿ã‚¤ãƒ—: {', '.join(set(stats['seeker_types']))}")
    print(f"  æ±‚äººã‚¿ã‚¤ãƒ—: {', '.join(set(stats['job_types']))}")
    print("")
    
    # ãƒ©ãƒ³ãƒ€ãƒ ã«æ±‚è·è€…ã¨æ±‚äººã‚’é¸æŠ
    seeker_profile, generated_job = data_manager.get_simulation_pair()
    
    print("ğŸ² ä»Šå›ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµ„ã¿åˆã‚ã›:")
    print(f"  æ±‚è·è€…: {seeker_profile['name']} ({seeker_profile.get('age', '?')}æ­³)")
    print(f"  ç¾è·: {seeker_profile.get('current_job', {}).get('company', '?')} - {seeker_profile.get('current_job', {}).get('role', '?')}")
    print(f"  ã‚¿ã‚°: {', '.join(seeker_profile.get('tags', []))}")
    print(f"  æ±‚äºº: {generated_job['title']} at {generated_job['company']}")
    print(f"  æ¥­ç•Œ: {generated_job.get('industry', '?')} / ä¼æ¥­ã‚¿ã‚¤ãƒ—: {generated_job.get('company_type', '?')}")
    print("")
    
    # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ HTMLç”Ÿæˆã®ãŸã‚ã®åˆæœŸåŒ–
    def init_realtime_html():
        html_template = f'''<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8">
  <title>è»¢è·AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ­ã‚°</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="refresh" content="3">
  <style>
    body {{
      font-family: 'Helvetica Neue', 'Arial', 'Hiragino Sans', 'Noto Sans JP', sans-serif;
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      margin: 0;
      padding: 2em;
      min-height: 100vh;
      color: white;
    }}
    .container {{
      max-width: 800px;
      margin: 0 auto;
    }}
    .header {{
      text-align: center;
      margin-bottom: 2em;
    }}
    h1 {{
      font-size: 2.5em;
      margin-bottom: 0.5em;
      font-weight: 300;
    }}
    .subtitle {{
      font-size: 1.2em;
      opacity: 0.9;
    }}
    .simulation-info {{
      background: rgba(255,255,255,0.1);
      border-radius: 15px;
      padding: 1.5em;
      margin: 1em 0;
      backdrop-filter: blur(10px);
    }}
    .progress-container {{
      background: rgba(255,255,255,0.1);
      border-radius: 15px;
      padding: 2em;
      margin: 2em 0;
      backdrop-filter: blur(10px);
    }}
    .progress-bar {{
      background: rgba(255,255,255,0.2);
      border-radius: 10px;
      height: 8px;
      margin: 1em 0;
      overflow: hidden;
    }}
    .progress-fill {{
      background: linear-gradient(90deg, #00ff88, #00ccff);
      height: 100%;
      border-radius: 10px;
      transition: width 0.5s ease;
    }}
    .current-step {{
      font-size: 1.3em;
      font-weight: 500;
      margin: 1em 0;
      padding: 1em;
      background: rgba(255,255,255,0.15);
      border-radius: 10px;
      border-left: 4px solid #00ff88;
    }}
    .steps-list {{
      margin-top: 2em;
    }}
    .step-item {{
      display: flex;
      align-items: center;
      padding: 0.8em 0;
      border-bottom: 1px solid rgba(255,255,255,0.1);
    }}
    .step-status {{
      width: 24px;
      height: 24px;
      border-radius: 50%;
      margin-right: 1em;
      display: flex;
      align-items: center;
      justify-content: center;
      font-size: 0.8em;
    }}
    .step-completed {{
      background: #00ff88;
      color: #000;
    }}
    .step-current {{
      background: #ffaa00;
      color: #000;
    }}
    .step-pending {{
      background: rgba(255,255,255,0.2);
      color: #fff;
    }}
    .step-text {{
      flex: 1;
    }}
    .loading-spinner {{
      width: 20px;
      height: 20px;
      border: 2px solid rgba(255,255,255,0.3);
      border-top: 2px solid white;
      border-radius: 50%;
      animation: spin 1s linear infinite;
      margin-left: 1em;
    }}
    @keyframes spin {{
      0% {{ transform: rotate(0deg); }}
      100% {{ transform: rotate(360deg); }}
    }}
    .completion-message {{
      text-align: center;
      font-size: 1.5em;
      margin: 2em 0;
      padding: 2em;
      background: rgba(0,255,136,0.2);
      border-radius: 15px;
      border: 2px solid #00ff88;
    }}
    .refresh-info {{
      text-align: center;
      opacity: 0.7;
      font-size: 0.9em;
      margin-top: 2em;
    }}
  </style>
</head>
<body>
  <div class="container">
    <div class="header">
      <h1>ğŸ¤– è»¢è·AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ</h1>
      <div class="subtitle">ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³</div>
    </div>
    
    <div class="simulation-info">
      <h3>ğŸ² ä»Šå›ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³</h3>
      <p><strong>æ±‚è·è€…:</strong> {seeker_profile['name']} ({seeker_profile.get('age', '?')}æ­³)</p>
      <p><strong>ç¾è·:</strong> {seeker_profile.get('current_job', {}).get('company', '?')} - {seeker_profile.get('current_job', {}).get('role', '?')}</p>
      <p><strong>ç‰¹å¾´:</strong> {', '.join(seeker_profile.get('tags', []))}</p>
      <p><strong>æ±‚äºº:</strong> {generated_job['title']} at {generated_job['company']}</p>
      <p><strong>æ¥­ç•Œ:</strong> {generated_job.get('industry', '?')} / {generated_job.get('company_type', '?')}</p>
    </div>
    
    <div class="progress-container">
      <div class="current-step">
        ğŸ“ ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³é–‹å§‹æº–å‚™ä¸­...
      </div>
      <div class="progress-bar">
        <div class="progress-fill" style="width: 0%"></div>
      </div>
      <div style="text-align: center; margin: 1em 0;">
        é€²æ—: 0/20 ã‚¹ãƒ†ãƒƒãƒ— (0.0%)
      </div>
      
      <div class="steps-list">
        <h3>å®Ÿè¡Œã‚¹ãƒ†ãƒƒãƒ—</h3>
        <div class="step-item">
          <div class="step-status step-pending">1</div>
          <div class="step-text">æº–å‚™ä¸­...</div>
        </div>
      </div>
      
      <div class="refresh-info">
        ã“ã®ãƒšãƒ¼ã‚¸ã¯3ç§’ã”ã¨ã«è‡ªå‹•æ›´æ–°ã•ã‚Œã¾ã™
      </div>
    </div>
  </div>
</body>
</html>'''
        
        with open(log_html_path, 'w', encoding='utf-8') as f:
            f.write(html_template)
        
        print(f"ğŸ“± ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ HTMLãƒ­ã‚°ã‚’é–‹å§‹: {log_html_path}")
        print(f"ãƒ–ãƒ©ã‚¦ã‚¶ã§ {os.path.abspath(log_html_path)} ã‚’é–‹ã„ã¦ãã ã•ã„")
    
    def update_progress(progress):
        nonlocal current_progress
        current_progress = progress
        update_realtime_html()
    
    # update_realtime_htmlé–¢æ•°ã‚’å®Œå…¨å®Ÿè£…
    def update_realtime_html(is_completed=False):
        nonlocal is_simulation_completed
        if is_completed:
            is_simulation_completed = True
        
        # å‹•çš„ãªé€²æ—è¨ˆç®—
        completed_count = len(completed_steps)
        
        # é€²è¡Œä¸­ã§ãªã„å ´åˆã€æœ€ä½ã§ã‚‚20ã‚¹ãƒ†ãƒƒãƒ—ã‚’äºˆæƒ³
        # å®Œäº†æ¸ˆã¿ã®å ´åˆã€å®Ÿéš›ã®ã‚¹ãƒ†ãƒƒãƒ—æ•°ã‚’ãã®ã¾ã¾ä½¿ç”¨
        if is_simulation_completed:
            total_steps = completed_count
            progress_percentage = 100
        else:
            # å®Ÿè¡Œä¸­ã¯å®Ÿéš›ã®ã‚¹ãƒ†ãƒƒãƒ—æ•°ã‚ˆã‚Šå¤šã‚ã«è¦‹ç©ã‚‚ã‚Š
            estimated_total = max(20, completed_count + 5)
            total_steps = estimated_total
            progress_percentage = min(95, (completed_count / total_steps) * 100)  # 95%ã¾ã§
        
        # ç¾åœ¨ã®ã‚¹ãƒ†ãƒƒãƒ—åˆ¤å®š
        current_step_text = current_progress if current_progress else "å¾…æ©Ÿä¸­..."
        
        # å®Œäº†æ™‚ã®å‡¦ç†
        if is_simulation_completed:
            current_step_text = "ğŸ‰ ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Œäº†ï¼"
        
        # å®Ÿéš›ã«å®Ÿè¡Œã•ã‚ŒãŸã‚¹ãƒ†ãƒƒãƒ—ãƒªã‚¹ãƒˆã‚’ä½¿ç”¨
        steps_html = ""
        for i, step_name in enumerate(completed_steps):
            status_class = "step-completed"
            status_icon = "âœ“"
            
            steps_html += f'''
            <div class="step-item">
              <div class="step-status {status_class}">{status_icon}</div>
              <div class="step-text">{step_name}</div>
            </div>'''
        
        # ç¾åœ¨é€²è¡Œä¸­ã®ã‚¹ãƒ†ãƒƒãƒ—ãŒã‚ã‚‹å ´åˆ
        if current_progress and not is_simulation_completed:
            steps_html += f'''
            <div class="step-item">
              <div class="step-status step-current">â—</div>
              <div class="step-text">{current_progress} <div class="loading-spinner"></div></div>
            </div>'''
        
        # å®Œäº†æ™‚ã®ç‰¹åˆ¥ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        completion_html = ""
        if is_simulation_completed:
            completion_html = '''
            <div class="completion-message">
              ğŸ‰ è»¢è·ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãŒå®Œäº†ã—ã¾ã—ãŸï¼<br>
              è©³ç´°ãªãƒ­ã‚°ã¯é™çš„ç‰ˆHTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã”ç¢ºèªãã ã•ã„ã€‚
            </div>'''
        
        # HTMLãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæ›´æ–°
        html_template = f'''<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8">
  <title>è»¢è·AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ­ã‚°</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="refresh" content="3">
  <style>
    body {{
      font-family: 'Helvetica Neue', 'Arial', 'Hiragino Sans', 'Noto Sans JP', sans-serif;
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      margin: 0;
      padding: 2em;
      min-height: 100vh;
      color: white;
    }}
    .container {{
      max-width: 800px;
      margin: 0 auto;
    }}
    .header {{
      text-align: center;
      margin-bottom: 2em;
    }}
    h1 {{
      font-size: 2.5em;
      margin-bottom: 0.5em;
      font-weight: 300;
    }}
    .subtitle {{
      font-size: 1.2em;
      opacity: 0.9;
    }}
    .simulation-info {{
      background: rgba(255,255,255,0.1);
      border-radius: 15px;
      padding: 1.5em;
      margin: 1em 0;
      backdrop-filter: blur(10px);
    }}
    .progress-container {{
      background: rgba(255,255,255,0.1);
      border-radius: 15px;
      padding: 2em;
      margin: 2em 0;
      backdrop-filter: blur(10px);
    }}
    .progress-bar {{
      background: rgba(255,255,255,0.2);
      border-radius: 10px;
      height: 8px;
      margin: 1em 0;
      overflow: hidden;
    }}
    .progress-fill {{
      background: linear-gradient(90deg, #00ff88, #00ccff);
      height: 100%;
      border-radius: 10px;
      transition: width 0.5s ease;
    }}
    .current-step {{
      font-size: 1.3em;
      font-weight: 500;
      margin: 1em 0;
      padding: 1em;
      background: rgba(255,255,255,0.15);
      border-radius: 10px;
      border-left: 4px solid #00ff88;
    }}
    .steps-list {{
      margin-top: 2em;
    }}
    .step-item {{
      display: flex;
      align-items: center;
      padding: 0.8em 0;
      border-bottom: 1px solid rgba(255,255,255,0.1);
    }}
    .step-status {{
      width: 24px;
      height: 24px;
      border-radius: 50%;
      margin-right: 1em;
      display: flex;
      align-items: center;
      justify-content: center;
      font-size: 0.8em;
    }}
    .step-completed {{
      background: #00ff88;
      color: #000;
    }}
    .step-current {{
      background: #ffaa00;
      color: #000;
    }}
    .step-pending {{
      background: rgba(255,255,255,0.2);
      color: #fff;
    }}
    .step-text {{
      flex: 1;
    }}
    .loading-spinner {{
      width: 20px;
      height: 20px;
      border: 2px solid rgba(255,255,255,0.3);
      border-top: 2px solid white;
      border-radius: 50%;
      animation: spin 1s linear infinite;
      margin-left: 1em;
    }}
    @keyframes spin {{
      0% {{ transform: rotate(0deg); }}
      100% {{ transform: rotate(360deg); }}
    }}
    .completion-message {{
      text-align: center;
      font-size: 1.5em;
      margin: 2em 0;
      padding: 2em;
      background: rgba(0,255,136,0.2);
      border-radius: 15px;
      border: 2px solid #00ff88;
    }}
    .refresh-info {{
      text-align: center;
      opacity: 0.7;
      font-size: 0.9em;
      margin-top: 2em;
    }}
  </style>
</head>
<body>
  <div class="container">
    <div class="header">
      <h1>ğŸ¤– è»¢è·AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ</h1>
      <div class="subtitle">ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³</div>
    </div>
    
    <div class="simulation-info">
      <h3>ğŸ² ä»Šå›ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³</h3>
      <p><strong>æ±‚è·è€…:</strong> {seeker_profile['name']} ({seeker_profile.get('age', '?')}æ­³)</p>
      <p><strong>ç¾è·:</strong> {seeker_profile.get('current_job', {}).get('company', '?')} - {seeker_profile.get('current_job', {}).get('role', '?')}</p>
      <p><strong>ç‰¹å¾´:</strong> {', '.join(seeker_profile.get('tags', []))}</p>
      <p><strong>æ±‚äºº:</strong> {generated_job['title']} at {generated_job['company']}</p>
      <p><strong>æ¥­ç•Œ:</strong> {generated_job.get('industry', '?')} / {generated_job.get('company_type', '?')}</p>
    </div>
    
    <div class="progress-container">
      <div class="current-step">
        {current_step_text}
      </div>
      <div class="progress-bar">
        <div class="progress-fill" style="width: {progress_percentage}%"></div>
      </div>
      <div style="text-align: center; margin: 1em 0;">
        é€²æ—: {completed_count}/{total_steps} ã‚¹ãƒ†ãƒƒãƒ— ({progress_percentage:.1f}%)
      </div>
      
      {completion_html}
      
      <div class="steps-list">
        <h3>å®Ÿè¡Œã‚¹ãƒ†ãƒƒãƒ—</h3>
        {steps_html}
      </div>
      
      <div class="refresh-info">
        ã“ã®ãƒšãƒ¼ã‚¸ã¯3ç§’ã”ã¨ã«è‡ªå‹•æ›´æ–°ã•ã‚Œã¾ã™
      </div>
    </div>
  </div>
</body>
</html>'''
        
        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ HTMLãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®æ›¸ãè¾¼ã¿
        with open(log_html_path, 'w', encoding='utf-8') as f:
            f.write(html_template)
        
        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤ºç”¨ã®å›ºå®šãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚‚ã‚³ãƒ”ãƒ¼
        with open('examples/logs/latest_simulation.html', 'w', encoding='utf-8') as f:
            f.write(html_template)
    
    def log_json(step, content):
        logs.append({"step": step, "content": content})
        with open(log_path, 'a', encoding='utf-8') as f:
            f.write(json.dumps({"step": step, "content": content}, ensure_ascii=False) + '\n')
    
    def log_md(step, content):
        with open(log_md_path, 'a', encoding='utf-8') as f:
            f.write(f'### {step}\n')
            if isinstance(content, dict):
                for k, v in content.items():
                    f.write(f'- **{k}**: {json.dumps(v, ensure_ascii=False, indent=2) if isinstance(v, (dict, list)) else v}\n')
            else:
                # ã¾ãšä¼šè©±ãƒ‘ãƒ¼ãƒˆã®ç™ºè¨€ã”ã¨ã«åˆ†å‰²ã™ã‚‹æ­£è¦åŒ–å‡¦ç†
                conversation_speakers = ["seeker:", "seekerAI:", "HR:", "EmployerAgent:"]
                # 1è¡Œã«è¤‡æ•°ç™ºè¨€ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã‚‚åˆ†å‰²
                def split_conversation(text):
                    import re
                    # å…ˆé ­ä»¥å¤–ã®ç™ºè¨€ãƒ©ãƒ™ãƒ«ã®å‰ã«æ”¹è¡Œã‚’æŒ¿å…¥
                    pattern = r'(?<!^)(' + '|'.join(re.escape(s) for s in conversation_speakers) + r')'
                    return re.sub(pattern, r'\n\1', text)
                
                # ä¼šè©±ãƒ†ã‚­ã‚¹ãƒˆã®æ•´å½¢ - ä½™åˆ†ãªè£…é£¾ã‚’å‰Šé™¤
                def clean_conversation_text(text):
                    # ä½™åˆ†ãªã€Œ**ã€ã‚„æ”¹è¡Œã‚’æ•´ç†
                    text = re.sub(r'\*\*\s*\n*\s*', '**', text)
                    # äºŒé‡ã‚¢ã‚¹ã‚¿ãƒªã‚¹ã‚¯ã®é–“ã«ä½™åˆ†ãªç©ºç™½ã‚„æ”¹è¡ŒãŒã‚ã‚‹å ´åˆã‚’ä¿®æ­£
                    text = re.sub(r'\*\*\s+([^*]+?)\s+\*\*', r'**\1**', text)
                    return text
                
                # ä¼šè©±ãƒ†ã‚­ã‚¹ãƒˆã‚’æ•´å½¢
                content_str = clean_conversation_text(str(content))
                normalized_content = split_conversation(content_str)
                lines = normalized_content.split('\n')
                
                # ä¼šè©±ãƒ‘ãƒ¼ãƒˆã‹ã©ã†ã‹åˆ¤å®š
                is_conversation = any(
                    l.strip().startswith(tuple(conversation_speakers))
                    for l in lines if l.strip()
                )
                # æ§‹é€ åŒ–ãƒ†ã‚­ã‚¹ãƒˆã‹ã©ã†ã‹åˆ¤å®šï¼ˆé¢æ¥å›ç­”ã€è©•ä¾¡ãªã©ï¼‰
                is_structured = any(
                    l.strip().startswith(("**å›ç­”:", "**è©•ä¾¡:", "**ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰", "ã€", "å›ç­”:", "è©•ä¾¡:", "ç†ç”±:", "æˆæœ:", "ã‚³ãƒ¡ãƒ³ãƒˆ:"))
                    for l in lines if l.strip()
                )
                # ç®‡æ¡æ›¸ããƒªã‚¹ãƒˆã‹ã©ã†ã‹åˆ¤å®š
                is_list = all(
                    l.strip().startswith(('-', 'ãƒ»', '*', '1.', '2.', '3.')) or not l.strip()
                    for l in lines if l.strip()
                )
                # ã‚»ã‚¯ã‚·ãƒ§ãƒ³æ§‹é€ ã‚’æŒã¤ã‹ã©ã†ã‹åˆ¤å®š
                has_sections = any(
                    'ã€' in l and 'ã€‘' in l
                    for l in lines if l.strip()
                )
                out = ''
                if is_conversation:
                    for para in lines:
                        if para.strip():
                            # ä½™åˆ†ãªã€Œ**ã€ã‚’å‰Šé™¤
                            clean_para = re.sub(r'\*\*\s*\n*\s*', '', para.strip())
                            out += f'{clean_para}  \n\n'
                elif is_structured:
                    for para in lines:
                        if para.strip():
                            if para.strip().startswith(('**', 'ã€')) or ':' in para.strip():
                                out += f'{para.strip()}  \n\n'
                            else:
                                out += f'{para.strip()}  \n'
                elif has_sections:
                    for para in lines:
                        if para.strip():
                            if 'ã€' in para and 'ã€‘' in para:
                                out += f'{para.strip()}  \n\n'
                            else:
                                out += f'{para.strip()}  \n'
                elif is_list:
                    for para in lines:
                        if para.strip():
                            out += f'{para.strip()}\n'
                else:
                    for para in lines:
                        if para.strip():
                            out += f'{para.strip()}\n\n'
                out = re.sub(r'\n{3,}', '\n\n', out)
                f.write(out)
            f.write('\n')
    
    def log_html(step, content):
        # ã‚¹ãƒ†ãƒƒãƒ—å®Œäº†ã‚’è¨˜éŒ²
        completed_steps.append(step)
        
        # ã‚¹ãƒ†ãƒƒãƒ—ã®åˆ†é¡ã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æ±ºå®š
        step_meta = classify_step(step, content)
        
        # ã‚»ã‚¯ã‚·ãƒ§ãƒ³æ§‹é€ ã§ç”Ÿæˆ
        html_section = f'''
<div class="content-section" data-view="{step_meta['view']}" data-process="{step_meta['process']}">
  <div class="section-header">
    <h2 class="section-title">{step}</h2>
    <div class="section-meta">
      <span class="meta-tag {step_meta['view']}">{step_meta['view_label']}</span>
      {f'<span class="meta-tag {step_meta["type"]}">{step_meta["type_label"]}</span>' if step_meta.get('type') else ''}
    </div>
  </div>
  <div class="section-content">
'''
        
        if isinstance(content, dict):
            html_section += '<ul>\n'
            for k, v in content.items():
                formatted_value = json.dumps(v, ensure_ascii=False, indent=2) if isinstance(v, (dict, list)) else v
                html_section += f'<li><strong>{k}</strong>: {formatted_value}</li>\n'
            html_section += '</ul>\n'
        else:
            content_str = str(content)
            
            # ä¼šè©±å½¢å¼ã®åˆ¤å®šã¨å‡¦ç†
            if step_meta['type'] == 'conversation':
                html_section += generate_chat_html(content_str, step_meta)
            
            # ã‚«ãƒ¼ãƒ‰å½¢å¼ã®åˆ¤å®šã¨å‡¦ç†
            elif step_meta['type'] in ['job-posting', 'resume', 'offer']:
                html_section += generate_card_html(content_str, step_meta)
            
            # çµæœãƒ»åˆ¤å®šã®å¼·èª¿è¡¨ç¤º
            elif step_meta['type'] == 'decision':
                html_section += generate_result_html(content_str, step_meta)
            
            # é¢æ¥Q&A
            elif step_meta['type'] == 'interview':
                html_section += generate_interview_html(content_str, step_meta)
            
            # ãã®ä»–ã®é€šå¸¸ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
            else:
                html_section += f'<p>{content_str.replace("\n", "<br>\n")}</p>\n'
        
        html_section += '''
  </div>
</div>
'''
        
        # æ—¢å­˜ã®HTMLã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®æœ€å¾Œã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’æ›´æ–°
        if html_content:
            html_content[-1] = html_content[-1].replace('current-step', 'completed-step')
        
        html_content.append(html_section)
        
        # é€²æ—è¡¨ç¤ºã‚’ã‚¯ãƒªã‚¢
        update_progress("")
        
        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ HTMLæ›´æ–°
        update_realtime_html()
    
    def classify_step(step, content):
        """ã‚¹ãƒ†ãƒƒãƒ—ã‚’åˆ†é¡ã—ã¦ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™"""
        content_str = str(content).lower()
        step_lower = step.lower()
        
        # åŸºæœ¬åˆ†é¡
        meta = {
            'view': 'all',
            'view_label': 'å…±é€š',
            'process': 'other',
            'type': 'text',
            'type_label': 'ãƒ†ã‚­ã‚¹ãƒˆ'
        }
        
        # ãƒ—ãƒ­ã‚»ã‚¹åˆ†é¡
        if any(kw in step_lower for kw in ['è»¢è·ç›¸è«‡', 'ä¼šè©±']):
            meta['process'] = 'consultation'
        elif any(kw in step_lower for kw in ['æ±‚äºº', 'æ¦‚è¦', 'æ¨ã—']):
            meta['process'] = 'job-proposal'
        elif any(kw in step_lower for kw in ['æ›¸é¡', 'é¸è€ƒ', 'å±¥æ­´æ›¸']):
            meta['process'] = 'document-screening'
        elif any(kw in step_lower for kw in ['é¢æ¥', 'interview']):
            meta['process'] = 'interview'
        elif any(kw in step_lower for kw in ['ã‚ªãƒ•ã‚¡ãƒ¼', 'äº¤æ¸‰', 'offer']):
            meta['process'] = 'offer'
        elif any(kw in step_lower for kw in ['åˆ¤æ–­', 'æ±ºæ–­', 'å—è«¾', 'è¾é€€']):
            meta['process'] = 'final-decision'
        
        # è¦–ç‚¹åˆ†é¡
        if any(kw in step_lower for kw in ['ä¼æ¥­å´', 'empai', 'simhr', 'hr', 'ä¼æ¥­åˆ¤å®š']):
            meta['view'] = 'company'
            meta['view_label'] = 'ä¼æ¥­è¦–ç‚¹'
        elif any(kw in step_lower for kw in ['æ±‚è·è€…å´', 'seeker', 'æ±‚è·è€…åˆ¤å®š']):
            meta['view'] = 'seeker'
            meta['view_label'] = 'æ±‚è·è€…è¦–ç‚¹'
        elif any(kw in step_lower for kw in ['åˆ¤å®š', 'åˆå¦', 'æ±ºæ–­', 'çµæœ']):
            meta['view'] = 'decision'
            meta['view_label'] = 'åˆ¤å®šãƒ»çµæœ'
        
        # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¿ã‚¤ãƒ—åˆ†é¡
        if any(speaker in content_str for speaker in ['seeker:', 'seekerai:', 'hr:', 'empai:', 'ğŸ‘¤', 'ğŸ¯', 'ğŸ‘¨â€ğŸ’¼', 'ğŸ‘©â€ğŸ’»', 'ğŸ¤–']):
            meta['type'] = 'conversation'
            meta['type_label'] = 'ä¼šè©±'
        elif any(kw in content_str for kw in ['ã€åŸºæœ¬æƒ…å ±ã€‘', 'ã€ã‚¹ã‚­ãƒ«ãƒ»æ¡ä»¶ã€‘', 'ã€ç‰¹å¾´ãƒ»ãƒŸãƒƒã‚·ãƒ§ãƒ³ã€‘']):
            meta['type'] = 'job-posting'
            meta['type_label'] = 'æ±‚äººç¥¨'
        elif any(kw in content_str for kw in ['ã€è·å‹™çµŒæ­´ã€‘', 'ã€ã‚¹ã‚­ãƒ«ã€‘', 'ã€è‡ªå·±prã€‘']):
            meta['type'] = 'resume'
            meta['type_label'] = 'å±¥æ­´æ›¸'
        elif any(kw in step_lower for kw in ['è³ªå•', 'å›ç­”', 'é¢æ¥']):
            meta['type'] = 'interview'
            meta['type_label'] = 'é¢æ¥'
        elif any(kw in step_lower for kw in ['åˆ¤å®š', 'åˆå¦', 'æ±ºæ–­', 'æœ€çµ‚æ±ºæ–­']):
            meta['type'] = 'decision'
            meta['type_label'] = 'åˆ¤å®š'
        elif any(kw in step_lower for kw in ['ã‚ªãƒ•ã‚¡ãƒ¼', 'äº¤æ¸‰']):
            meta['type'] = 'offer'
            meta['type_label'] = 'ã‚ªãƒ•ã‚¡ãƒ¼'
        
        return meta
    
    def generate_chat_html(content_str, meta):
        """ãƒãƒ£ãƒƒãƒˆå½¢å¼ã®HTMLç”Ÿæˆ"""
        html = '<div class="chat-container">\n'
        
        # ã‚¢ã‚¤ã‚³ãƒ³ä»˜ãç™ºè¨€è€…ã‚’è­˜åˆ¥
        icon_speakers = {
            'ğŸ‘¤': ('seeker', 'æ±‚è·è€…'),
            'ğŸ¯': ('agent', 'è»¢è·AI'),
            'ğŸ‘¨â€ğŸ’¼': ('hr', 'HR'),
            'ğŸ‘©â€ğŸ’»': ('hr', 'é¢æ¥å®˜'),
            'ğŸ¤–': ('empai', 'AI')
        }
        
        # å¾“æ¥ã®ç™ºè¨€è€…ã‚‚è­˜åˆ¥
        text_speakers = {
            'seeker:': ('seeker', 'æ±‚è·è€…'),
            'seekerai:': ('agent', 'è»¢è·AI'),
            'hr:': ('hr', 'äººäº‹'),
            'employeragent:': ('hr', 'ä¼æ¥­æ‹…å½“')
        }
        
        # è¡Œã”ã¨ã«å‡¦ç†
        lines = content_str.split('\n')
        current_speaker = ""
        current_class = ""
        current_name = ""
        message = ""
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            # ã‚¢ã‚¤ã‚³ãƒ³ä»˜ãç™ºè¨€è€…ã‚’æ¤œå‡º
            found_speaker = False
            for icon, (class_name, display_name) in icon_speakers.items():
                if line.startswith(icon):
                    if message and current_speaker:
                        html += generate_chat_bubble(message, current_class, current_name)
                    current_speaker = icon
                    current_class = class_name
                    current_name = display_name
                    message = line[len(icon):].strip()
                    found_speaker = True
                    break
            
            if not found_speaker:
                # å¾“æ¥ã®ç™ºè¨€è€…ã‚’æ¤œå‡º
                line_lower = line.lower()
                for speaker, (class_name, display_name) in text_speakers.items():
                    if line_lower.startswith(speaker):
                        if message and current_speaker:
                            html += generate_chat_bubble(message, current_class, current_name)
                        current_speaker = speaker
                        current_class = class_name
                        current_name = display_name
                        message = line[len(speaker):].strip()
                        found_speaker = True
                        break
                
                if not found_speaker and current_speaker:
                    # ç¶™ç¶šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
                    message += " " + line
        
        # æœ€å¾Œã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‡ºåŠ›
        if message and current_speaker:
            html += generate_chat_bubble(message, current_class, current_name)
        
        html += '</div>\n'
        return html
    
    def generate_chat_bubble(message, class_name, display_name):
        """ãƒãƒ£ãƒƒãƒˆãƒãƒ–ãƒ«HTMLç”Ÿæˆ"""
        return f'''
<div class="chat-bubble {class_name}">
  <div class="sender">{display_name}</div>
  {message}
</div>
'''
    
    def generate_card_html(content_str, meta):
        """ã‚«ãƒ¼ãƒ‰å½¢å¼ã®HTMLç”Ÿæˆ"""
        card_class = meta['type']
        title = meta['type_label']
        
        # æ§‹é€ åŒ–ã•ã‚ŒãŸæƒ…å ±ã‚’è§£æ
        content_formatted = content_str.replace('\n', '<br>\n')
        content_formatted = re.sub(r'\*\*ã€(.+?)ã€‘\*\*', r'<h4>\1</h4>', content_formatted)
        content_formatted = re.sub(r'\*\*(.+?)\*\*', r'<strong>\1</strong>', content_formatted)
        
        return f'''
<div class="info-card {card_class}">
  <div class="card-header">
    <h3 class="card-title">{title}</h3>
  </div>
  {content_formatted}
</div>
'''
    
    def generate_result_html(content_str, meta):
        """çµæœãƒ»åˆ¤å®šã®HTMLç”Ÿæˆ"""
        # ãƒã‚¸ãƒ†ã‚£ãƒ–ãƒ»ãƒã‚¬ãƒ†ã‚£ãƒ–åˆ¤å®š
        is_positive = any(kw in content_str for kw in ['åˆæ ¼', 'é€šé', 'å—è«¾', 'ç¶™ç¶š', 'é€²ã‚€', 'ã‚ªãƒ•ã‚¡ãƒ¼æ®µéš'])
        is_negative = any(kw in content_str for kw in ['ä¸åˆæ ¼', 'è¦‹é€ã‚Š', 'è¾é€€', 'çµ‚äº†'])
        
        result_class = 'positive' if is_positive else 'negative' if is_negative else ''
        
        return f'''
<div class="result-highlight {result_class}">
  {content_str.replace('\n', '<br>\n')}
</div>
'''
    
    def generate_interview_html(content_str, meta):
        """é¢æ¥Q&Aå½¢å¼ã®HTMLç”Ÿæˆ"""
        title = "é¢æ¥è³ªå•" if "è³ªå•" in meta['type_label'] else "é¢æ¥å›ç­”"
        
        # æ§‹é€ åŒ–ã•ã‚ŒãŸæƒ…å ±ã‚’èª¿æ•´
        content_formatted = re.sub(r'\*\*(.+?):\*\*', r'<strong>\1:</strong>', content_str)
        
        return f'''
<div class="info-card interview">
  <div class="card-header">
    <h3 class="card-title">{title}</h3>
  </div>
  <p>{content_formatted.replace('\n', '<br>\n')}</p>
</div>
'''
    
    def generate_html_file():
        # æœ€çµ‚çš„ãªHTMLãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆï¼ˆå¾“æ¥ã®æ©Ÿèƒ½ï¼‰
        template_path = 'logs/è»¢è·AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ_ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚°_UIå½¢å¼_æœ€çµ‚ç‰ˆ.html'
        try:
            with open(template_path, 'r', encoding='utf-8') as template_file:
                template = template_file.read()
            
            # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æŒ¿å…¥ä½ç½®ã‚’ç‰¹å®š
            content_placeholder = '<!-- Canvasã‹ã‚‰è²¼ã‚Šä»˜ã‘ãŸæœ€çµ‚ç‰ˆãŒã“ã“ã«å…¥ã‚Šã¾ã™ -->'
            complete_html = template.replace(content_placeholder, '\n'.join(html_content))
            
            # é™çš„ç‰ˆã®ãƒ•ã‚¡ã‚¤ãƒ«å
            static_html_path = log_html_path.replace('.html', '_static.html')
            with open(static_html_path, 'w', encoding='utf-8') as f:
                f.write(complete_html)
            print(f"ğŸ“„ é™çš„ç‰ˆHTMLãƒ­ã‚°ã‚‚ä¿å­˜: {static_html_path}")
        except FileNotFoundError:
            print(f"è­¦å‘Š: HTMLãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ« '{template_path}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    
    def step_title(title):
        nonlocal step_counter
        s = f"{step_counter}. {title}"
        step_counter += 1
        return s

    def format_job_posting_md(job):
        # åŸºæœ¬æƒ…å ±
        s = '**ã€åŸºæœ¬æƒ…å ±ã€‘**\n'
        s += f'- ãƒã‚¸ã‚·ãƒ§ãƒ³: {job.get("position", "")}' + '\n'
        s += f'- ä¼šç¤¾: {job.get("company", "")}' + '\n'
        s += f'- èƒŒæ™¯: {job.get("background", "")}' + '\n'
        s += f'- å¹´å: {job.get("salary", "")}ä¸‡å††ã€œ' + '\n'
        s += f'- åƒãæ–¹: {job.get("work_style", "")}' + '\n'
        # ã‚¹ã‚­ãƒ«ãƒ»æ¡ä»¶
        s += '\n**ã€ã‚¹ã‚­ãƒ«ãƒ»æ¡ä»¶ã€‘**\n'
        if job.get("tech_stack"):
            s += '- æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯:\n'
            for skill in job["tech_stack"]:
                s += f'    - {skill}\n'
        # ã‚«ãƒ«ãƒãƒ£ãƒ¼
        if job.get("culture_keywords"):
            s += '- ã‚«ãƒ«ãƒãƒ£ãƒ¼ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰:\n'
            for kw in job["culture_keywords"]:
                s += f'    - {kw}\n'
        # ç‰¹å¾´ãƒ»ãƒŸãƒƒã‚·ãƒ§ãƒ³
        s += '\n**ã€ç‰¹å¾´ãƒ»ãƒŸãƒƒã‚·ãƒ§ãƒ³ã€‘**\n'
        if job.get("mission"):
            s += f'- ãƒŸãƒƒã‚·ãƒ§ãƒ³: {job["mission"]}\n'
        if job.get("team"):
            s += f'- ãƒãƒ¼ãƒ : {job["team"]}\n'
        if job.get("growth"):
            s += f'- æˆé•·æ©Ÿä¼š: {job["growth"]}\n'
        if job.get("unique"):
            s += f'- ç‹¬è‡ªã®é­…åŠ›: {job["unique"]}\n'
        if job.get("persona"):
            s += f'- æ±‚ã‚ã‚‹äººç‰©åƒ: {job["persona"]}\n'
        return s

    # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ HTMLåˆæœŸåŒ–
    init_realtime_html()

    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆæœŸåŒ–ï¼ˆseeker_agentã‚’å…ˆã«ï¼‰
    seeker_agent = SeekerAgent()
    simulated_hr = SimulatedHR()
    simulated_hr.llm = seeker_agent.llm
    employer_agent = EmployerAgent()

    # æ—¢å­˜ã®HRè¦æœ›ç”Ÿæˆã¯æ®‹ã™ï¼ˆäº’æ›æ€§ã®ãŸã‚ï¼‰
    hr_needs = simulated_hr.provide_needs()
    log_json("0.1. SimulatedHRã®æ±‚äººè¦æœ›", hr_needs)
    log_md("0.1. SimulatedHRã®æ±‚äººè¦æœ›", hr_needs)
    log_html("0.1. SimulatedHRã®æ±‚äººè¦æœ›", hr_needs)

    # HRã¨EmployerAgentã®ä¼šè©±ã‚’ç”Ÿæˆ
    with open("prompts/hr_employer_conversation.txt", encoding="utf-8") as f:
        hr_emp_conv_prompt = f.read().strip()
    hr_emp_conv_prompt_filled = hr_emp_conv_prompt.format(hr_needs=json.dumps(hr_needs, ensure_ascii=False, indent=2))
    # LLMã§ä¼šè©±ç”Ÿæˆï¼ˆseeker_agentã‚’æµç”¨ï¼‰
    hr_emp_conversation = await seeker_agent.llm.generate_content_async(
        hr_emp_conv_prompt_filled, 
        agent_name="HRã¨Employerã®ä¼šè©±ç”Ÿæˆ",
        progress_callback=update_progress
    )
    
    # ä¼šè©±ã®æ•´å½¢å‡¦ç†
    # LLMã®å‡ºåŠ›ã‹ã‚‰ä½™åˆ†ãªã€Œ**ã€ã‚„æ”¹è¡Œã‚’é™¤å»ã—ã€æ•´å½¢ã™ã‚‹
    hr_emp_conversation_clean = re.sub(r'\*\*\s*\n*\s*', '**', hr_emp_conversation)
    
    log_json("0.1.5. HRã¨EmployerAgentã®ä¼šè©±", hr_emp_conversation_clean)
    log_md("0.1.5. HRã¨EmployerAgentã®ä¼šè©±", hr_emp_conversation_clean)
    log_html("0.1.5. HRã¨EmployerAgentã®ä¼šè©±", hr_emp_conversation_clean)

    # DataManagerã§ç”Ÿæˆã•ã‚ŒãŸæ±‚äººã‚’ä½¿ç”¨ï¼ˆHRè¦æœ›ãƒ™ãƒ¼ã‚¹ã®æ±‚äººç”Ÿæˆã¯å¼•ãç¶šãå®Ÿè¡Œã™ã‚‹ãŒã€å®Ÿéš›ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯ä½¿ã‚ãªã„ï¼‰
    traditional_job_posting = employer_agent.create_job_posting(simulated_hr)
    log_json("0.2. EmployerAgentãŒç”Ÿæˆã—ãŸå¾“æ¥æ±‚äººç¥¨ï¼ˆå‚è€ƒï¼‰", traditional_job_posting)
    formatted_traditional_job_posting = format_job_posting_md(traditional_job_posting)
    log_md("0.2. EmployerAgentãŒç”Ÿæˆã—ãŸå¾“æ¥æ±‚äººç¥¨ï¼ˆå‚è€ƒï¼‰", formatted_traditional_job_posting)
    log_html("0.2. EmployerAgentãŒç”Ÿæˆã—ãŸå¾“æ¥æ±‚äººç¥¨ï¼ˆå‚è€ƒï¼‰", formatted_traditional_job_posting)
    print("\nã€å¾“æ¥ã®æ±‚äººç”Ÿæˆï¼ˆå‚è€ƒï¼‰ã€‘")
    print(traditional_job_posting)

    # DataManagerã§é¸æŠã—ãŸæ±‚äººç¥¨ã‚’å®Ÿéš›ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ä½¿ç”¨
    log_json("0.3. ä»Šå›ä½¿ç”¨ã™ã‚‹æ±‚äººç¥¨", generated_job)
    formatted_generated_job = format_job_posting_md(generated_job)
    log_md("0.3. ä»Šå›ä½¿ç”¨ã™ã‚‹æ±‚äººç¥¨", formatted_generated_job)
    log_html("0.3. ä»Šå›ä½¿ç”¨ã™ã‚‹æ±‚äººç¥¨", formatted_generated_job)
    print("\nã€ä»Šå›ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ä½¿ç”¨ã™ã‚‹æ±‚äººç¥¨ã€‘")
    print(generated_job)

    # job_listã‚’é¸æŠã•ã‚ŒãŸæ±‚äººã¨ã™ã‚‹
    job_list = [generated_job]

    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆæœŸåŒ–
    simulated_seeker = SimulatedSeeker()
    # é¢æ¥å®˜æƒ…å ±ã‚’æ±‚äººãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å–å¾—
    interviewer_info = None
    if generated_job.get("interviewers"):
        interviewer_info = generated_job["interviewers"][0]  # æœ€åˆã®é¢æ¥å®˜ã‚’ä½¿ç”¨
    
    if interviewer_info is None:
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®é¢æ¥å®˜æƒ…å ±
        interviewer_info = {
            "name": "ç”°ä¸­éƒ¨é•·",
            "role": "é–‹ç™ºéƒ¨é•·",
            "availability": [
                {
                    "start": "2025-01-20T14:00:00+09:00",
                    "end": "2025-01-20T18:00:00+09:00"
                },
                {
                    "start": "2025-01-22T10:00:00+09:00",
                    "end": "2025-01-22T16:00:00+09:00"
                }
            ]
        }
    
    interviewer = SimulatedInterviewer(info=interviewer_info)

    # --- seekerã¨seekerAIã®ä¼šè©±ã‚’ã¾ã¨ã‚ã¦ç”Ÿæˆãƒ»è¡¨ç¤º ---
    conversation_example = await simulated_seeker.start_conversation(seeker_profile)
    print("\nã€è»¢è·ç›¸è«‡ã®ä¼šè©±ã€‘")
    print(conversation_example)
    log_json("1. è»¢è·ç›¸è«‡ã®ä¼šè©±", conversation_example)
    log_md("1. è»¢è·ç›¸è«‡ã®ä¼šè©±", conversation_example)
    log_html("1. è»¢è·ç›¸è«‡ã®ä¼šè©±", conversation_example)

    # seekerãŒæ±‚äººã®è©±ã‚’èããŸã„æ„æ€ã‚’ç¤ºã—ãŸã‚‰æ±‚äººææ¡ˆãƒ•ãƒ­ãƒ¼ã¸
    lines = [l.strip() for l in conversation_example.strip().split('\n') if l.strip()]
    seeker_lines = [l for l in lines if l.startswith("seeker:")]
    last_seeker_line = seeker_lines[-1] if seeker_lines else ""

    # ã€Œæ±‚äººã®è©±ã‚’èããŸã„ã€æ„æ€ã‚’ç¤ºã™ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
    hear_keywords = [
        "ãœã²èã‹ã›ã¦", "èˆˆå‘³ã‚ã‚‹", "èã„ã¦ã¿ãŸã„", "ãã®è©±ã€è©³ã—ã", "è©±ã‚’èããŸã„", "æ±‚äººã®è©³ç´°", "ã©ã‚“ãªæ±‚äºº", "æ•™ãˆã¦", "èª¬æ˜ã—ã¦", "çŸ¥ã‚ŠãŸã„", "æ±‚äººã«ã¤ã„ã¦", "æ±‚äººã‚’æ•™ãˆã¦", "æ±‚äººã®è©±ã‚’èããŸã„", "æ±‚äººã®è©³ç´°ã‚’çŸ¥ã‚ŠãŸã„", "è©³ã—ãèã‹ã›ã¦"
    ]
    if any(kw in last_seeker_line for kw in hear_keywords):
        # æ±‚äººææ¡ˆãƒ•ãƒ­ãƒ¼
        step = step_title("æ±‚äººæ¦‚è¦æç¤º")
        job = job_list[0]  # 1ä»¶ã®ã¿å‰æ
        job_summary = await seeker_agent.propose_job_summary(job, progress_callback=update_progress)
        print("\nã€ã‚­ãƒ£ãƒªã‚¢ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ã®æ±‚äººæ¦‚è¦ã€‘")
        print(job_summary)
        log_json(step, job_summary)
        log_md(step, job_summary)
        log_html(step, job_summary)

        step = step_title("æ±‚äººæ¨ã—ãƒ—ãƒ¬ã‚¼ãƒ³")
        job_pitch = await seeker_agent.propose_job_pitch(seeker_profile, job, progress_callback=update_progress)
        print("\nã€ã‚­ãƒ£ãƒªã‚¢ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ã®æ¨ã—ãƒã‚¤ãƒ³ãƒˆã€‘")
        print(job_pitch)
        log_json(step, job_pitch)
        log_md(step, job_pitch)
        log_html(step, job_pitch)

        # --- å¿œå‹Ÿæ„æ€ç¢ºèª ---
        step = step_title("å¿œå‹Ÿæ„æ€ç¢ºèª")
        job_intent = await simulated_seeker.job_intent(job_pitch)
        print("\nã€æ±‚è·è€…ã®å¿œå‹Ÿæ„æ€ã€‘")
        print(job_intent)
        log_json(step, job_intent)
        log_md(step, job_intent)
        log_html(step, job_intent)

        # --- å¿œå‹Ÿç†ç”±ï¼ˆå±¥æ­´æ›¸ï¼‹AIæ¨è–¦ã‚³ãƒ¡ãƒ³ãƒˆä¸€ä½“å‹ï¼‰ç”Ÿæˆ ---
        step = step_title("å¿œå‹Ÿç†ç”±ãƒ»AIæ¨è–¦ä»˜ãå±¥æ­´æ›¸")
        application_reason = await simulated_seeker.application_reason(seeker_profile, job_list[0])
        print("\nã€å¿œå‹Ÿç†ç”±ãƒ»AIæ¨è–¦ä»˜ãå±¥æ­´æ›¸ã€‘")
        print(application_reason)
        log_json(step, application_reason)
        log_md(step, application_reason)
        log_html(step, application_reason)

        if any(kw in job_intent for kw in ["è¦‹é€", "å¿œå‹Ÿã—ãªã„", "è¾é€€", "ã‚„ã‚ã‚‹", "è€ƒãˆãŸã„"]):
            print("å¿œå‹Ÿè¾é€€ã®ãŸã‚ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
            update_realtime_html(is_completed=True)  # å®Œäº†çŠ¶æ…‹ã«æ›´æ–°
            generate_html_file()  # HTMLç”Ÿæˆ
            return
                
        # --- æ›¸é¡é¸è€ƒãƒ—ãƒ­ã‚»ã‚¹ï¼ˆæ–°ãƒ•ãƒ­ãƒ¼ï¼‰ ---
        step = step_title("å±¥æ­´æ›¸æå‡º")
        resume = seeker_agent.generate_resume(seeker_profile)
        print("\nã€å±¥æ­´æ›¸ãƒ»è·å‹™çµŒæ­´æ›¸ã€‘")
        print(resume)
        log_json(step, resume)
        log_md(step, resume)
        log_html(step, resume)

        step = step_title("empaiã«ã‚ˆã‚‹æ›¸é¡å¯©æŸ»")
        empai_judgement = await employer_agent.screen_resume_llm(resume)
        print("\nã€empaiã®æ›¸é¡å¯©æŸ»ã€‘")
        print(empai_judgement["raw"])
        log_json(step, empai_judgement)
        log_md(step, empai_judgement["raw"])
        log_html(step, empai_judgement["raw"])

        step = step_title("simhrã®æ„è¦‹")
        simhr_opinion = await simulated_hr.opine_on_resume_screening(resume, empai_judgement)
        print("\nã€simhrã®æ„è¦‹ã€‘")
        print(simhr_opinion["raw"])
        log_json(step, simhr_opinion)
        log_md(step, simhr_opinion["raw"])
        log_html(step, simhr_opinion["raw"])

        # --- æœ€çµ‚åˆå¦æ±ºå®š ---
        step = step_title("æ›¸é¡é¸è€ƒãƒ»æœ€çµ‚åˆ¤å®š")
        # ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ­ã‚¸ãƒƒã‚¯ä¾‹ï¼šempaiãŒåˆæ ¼ã§simhrãŒè³›æˆâ†’åˆæ ¼ã€ãã‚Œä»¥å¤–ã¯ä¸åˆæ ¼
        if empai_judgement["decision"] == "åˆæ ¼" and simhr_opinion["stance"] == "agree":
            final_result = "åˆæ ¼"
            final_reason = f"empaiãƒ»simhrã¨ã‚‚ã«åˆæ ¼åˆ¤æ–­ã€‚ç†ç”±: {empai_judgement['reason']} / {simhr_opinion['reason']}"
        else:
            final_result = "ä¸åˆæ ¼"
            final_reason = f"empaiã¾ãŸã¯simhrãŒä¸åˆæ ¼ãƒ»åå¯¾åˆ¤æ–­ã€‚ç†ç”±: {empai_judgement['reason']} / {simhr_opinion['reason']}"
        print(f"\nã€æ›¸é¡é¸è€ƒãƒ»æœ€çµ‚åˆ¤å®šã€‘{final_result}\n{final_reason}")
        log_json(step, {"result": final_result, "reason": final_reason})
        log_md(step, f"åˆå¦: {final_result}\nç†ç”±: {final_reason}")
        log_html(step, f"åˆå¦: {final_result}\nç†ç”±: {final_reason}")
        # ä¸åˆæ ¼ã®å ´åˆã¯çµ‚äº†
        if final_result == "ä¸åˆæ ¼":
            print("æ›¸é¡é¸è€ƒã§ä¸åˆæ ¼ã®ãŸã‚ã€ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
            update_realtime_html(is_completed=True)  # å®Œäº†çŠ¶æ…‹ã«æ›´æ–°
            generate_html_file()  # HTMLç”Ÿæˆ
            return
        
        # åˆæ ¼ã®å ´åˆã¯é¢æ¥ãƒ—ãƒ­ã‚»ã‚¹ã«é€²ã‚€
        print("æ›¸é¡é¸è€ƒã«åˆæ ¼ã—ã¾ã—ãŸã€‚é¢æ¥ãƒ—ãƒ­ã‚»ã‚¹ã«é€²ã¿ã¾ã™ã€‚")

        # --- é¢æ¥ãƒ—ãƒ­ã‚»ã‚¹å¤šæ®µéšåŒ– ---
        interview_stages = ["ä¸€æ¬¡é¢æ¥", "äºŒæ¬¡é¢æ¥", "æœ€çµ‚é¢æ¥"]
        interview_results = []  # å„é¢æ¥ã®çµæœã‚’ä¿å­˜
        scheduled_interviews = {}  # å„ã‚¹ãƒ†ãƒ¼ã‚¸ã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æƒ…å ±ã‚’ä¿å­˜
        
        # é¢æ¥å®˜æƒ…å ±ã‚’ jobs.jsonã‹ã‚‰å–å¾—ï¼ˆè¤‡æ•°ã‚¹ãƒ†ãƒ¼ã‚¸å¯¾å¿œï¼‰
        stage_interviewers = {}
        for job in jobs:
            if job.get("interviewers"):
                for interviewer in job["interviewers"]:
                    stage = interviewer.get("stage", "ä¸€æ¬¡é¢æ¥")
                    stage_interviewers[stage] = interviewer
                break
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šå„ã‚¹ãƒ†ãƒ¼ã‚¸ã®é¢æ¥å®˜ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆ
        if not stage_interviewers:
            stage_interviewers = {
                "ä¸€æ¬¡é¢æ¥": {
                    "name": "ç”°ä¸­éƒ¨é•·", "role": "é–‹ç™ºéƒ¨é•·",
                    "email": "tanaka@company.co.jp", "scheduling_method": "calendar",
                    "interview_duration": 45,
                    "availability": [
                        {"start": "2025-01-20T14:00:00+09:00", "end": "2025-01-20T18:00:00+09:00"},
                        {"start": "2025-01-22T10:00:00+09:00", "end": "2025-01-22T16:00:00+09:00"}
                    ]
                },
                "äºŒæ¬¡é¢æ¥": {
                    "name": "ä½è—¤ãƒªãƒ¼ãƒ€ãƒ¼", "role": "ãƒ†ãƒƒã‚¯ãƒªãƒ¼ãƒ‰",
                    "email": "sato@company.co.jp", "scheduling_method": "email",
                    "interview_duration": 60, "availability": None, "preferred_times": "å¹³æ—¥ 10:00-18:00"
                },
                "æœ€çµ‚é¢æ¥": {
                    "name": "å±±æœ¬CTO", "role": "æŠ€è¡“è²¬ä»»è€…",
                    "email": "yamamoto@company.co.jp", "scheduling_method": "calendar",
                    "interview_duration": 60,
                    "availability": [
                        {"start": "2025-01-24T14:00:00+09:00", "end": "2025-01-24T18:00:00+09:00"}
                    ]
                }
            }
        
        for i, stage in enumerate(interview_stages):
            print(f"\nã€{stage}ã€‘")
            
            # --- ğŸ†• å„ã‚¹ãƒ†ãƒ¼ã‚¸ã§ã®æ—¥ç¨‹èª¿æ•´ ---
            step = step_title(f"{stage}ãƒ»æ—¥ç¨‹èª¿æ•´")
            current_interviewer_info = stage_interviewers.get(stage)
            
            if current_interviewer_info:
                print(f"\nã€{stage}ãƒ»æ—¥ç¨‹èª¿æ•´ã€‘")
                print(f"é¢æ¥å®˜: {current_interviewer_info['name']} ({current_interviewer_info['role']})")
                
                # é¢æ¥å®˜ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
                stage_interviewer = SimulatedInterviewer(info=current_interviewer_info)
                
                # æ—¥ç¨‹èª¿æ•´å®Ÿè¡Œ
                schedule_result = stage_interviewer.schedule_interview(
                    seeker_data=seeker_profile,
                    stage=stage,
                    company_name=job_list[0].get("company", ""),
                    position=job_list[0].get("title", "")
                )
                
                if schedule_result:
                    if isinstance(schedule_result, dict) and schedule_result.get("status") == "email_sent":
                        # ãƒ¡ãƒ¼ãƒ«é€ä¿¡ã®å ´åˆ
                        print("ğŸ“§ é¢æ¥å®˜ã¸ã®ãƒ¡ãƒ¼ãƒ«é€ä¿¡ãŒå®Œäº†ã—ã¾ã—ãŸã€‚è¿”ä¿¡å¾…ã¡ã§ã™ã€‚")
                        
                        # ğŸ†• ãƒ¡ãƒ¼ãƒ«è¿”ä¿¡ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆï¼ˆãƒ‡ãƒ¢ç”¨ï¼‰
                        print(f"\nã€{stage}ãƒ»é¢æ¥å®˜è¿”ä¿¡ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã€‘")
                        simulated_reply = stage_interviewer.schedule_agent.email_agent.simulate_interviewer_reply(
                            schedule_result["candidate_slots"], 
                            "positive"
                        )
                        print("ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆè¿”ä¿¡:")
                        print(simulated_reply)
                        
                        # è¿”ä¿¡å‡¦ç†
                        reply_result = stage_interviewer.schedule_agent.process_interview_reply(
                            schedule_result["request_id"], 
                            simulated_reply
                        )
                        
                        if reply_result["status"] == "confirmed":
                            scheduled_slot = reply_result["confirmed_slot"]
                            interview_format = reply_result.get("interview_format", "ã‚ªãƒ³ãƒ©ã‚¤ãƒ³")
                            print(f"âœ… {stage}ã®æ—¥ç¨‹ç¢ºå®š: {simulated_reply[:30]}...")
                        else:
                            print(f"âŒ {stage}ã®è¿”ä¿¡å‡¦ç†å¤±æ•—: {reply_result['message']}")
                            scheduled_slot = None
                    else:
                        # ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼è‡ªå‹•èª¿æ•´ã®å ´åˆ
                        scheduled_slot = schedule_result
                        interview_format = "ã‚ªãƒ³ãƒ©ã‚¤ãƒ³"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
                    
                    if scheduled_slot:
                        # æ±‚è·è€…ã¸ã®é€šçŸ¥
                        seeker_response = simulated_seeker.notify_interview_scheduled(
                            scheduled_slot, 
                            current_interviewer_info.get("name", "é¢æ¥å®˜")
                        )
                        
                        # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æƒ…å ±ã‚’ä¿å­˜
                        scheduled_interviews[stage] = {
                            "scheduled_slot": scheduled_slot,
                            "interviewer_info": current_interviewer_info,
                            "interview_format": interview_format,
                            "seeker_response": seeker_response
                        }
                        
                        # ãƒ­ã‚°ã«è¨˜éŒ²
                        schedule_log = {
                            "stage": stage,
                            "scheduled_start": scheduled_slot["start"],
                            "scheduled_end": scheduled_slot["end"],
                            "interviewer_name": current_interviewer_info.get("name", "é¢æ¥å®˜"),
                            "interviewer_role": current_interviewer_info.get("role", "é¢æ¥å®˜"),
                            "interview_format": interview_format,
                            "seeker_response": seeker_response
                        }
                        log_json(step, schedule_log)
                        log_md(step, f"{stage}æ—¥ç¨‹èª¿æ•´å®Œäº†\n- æ—¥æ™‚: {scheduled_slot['start']} ã€œ {scheduled_slot['end']}\n- é¢æ¥å®˜: {current_interviewer_info.get('name', 'é¢æ¥å®˜')}\n- å½¢å¼: {interview_format}\n- æ±‚è·è€…å¿œç­”: {seeker_response}")
                        log_html(step, f"{stage}æ—¥ç¨‹èª¿æ•´å®Œäº†\næ—¥æ™‚: {scheduled_slot['start']} ã€œ {scheduled_slot['end']}\né¢æ¥å®˜: {current_interviewer_info.get('name', 'é¢æ¥å®˜')}\nå½¢å¼: {interview_format}")
                    else:
                        print(f"âš ï¸ {stage}ã®æ—¥ç¨‹èª¿æ•´ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                        log_json(step, {"result": "æ—¥ç¨‹èª¿æ•´å¤±æ•—", "stage": stage})
                        log_md(step, f"{stage}æ—¥ç¨‹èª¿æ•´å¤±æ•—")
                        log_html(step, f"{stage}æ—¥ç¨‹èª¿æ•´å¤±æ•—")
                        print("æ—¥ç¨‹èª¿æ•´ãŒã§ããªã„ãŸã‚ã€ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
                        update_realtime_html(is_completed=True)
                        generate_html_file()
                        return
                else:
                    print(f"âš ï¸ {stage}ã®æ—¥ç¨‹èª¿æ•´ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                    log_json(step, {"result": "æ—¥ç¨‹èª¿æ•´å¤±æ•—", "stage": stage})
                    log_md(step, f"{stage}æ—¥ç¨‹èª¿æ•´å¤±æ•—")
                    log_html(step, f"{stage}æ—¥ç¨‹èª¿æ•´å¤±æ•—")
                    print("æ—¥ç¨‹èª¿æ•´ãŒã§ããªã„ãŸã‚ã€ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
                    update_realtime_html(is_completed=True)
                    generate_html_file()
                    return
            else:
                print(f"âš ï¸ {stage}ã®é¢æ¥å®˜æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
                log_json(step, {"result": "é¢æ¥å®˜æƒ…å ±ãªã—", "stage": stage})
                log_md(step, f"{stage}é¢æ¥å®˜æƒ…å ±ãªã—")
                log_html(step, f"{stage}é¢æ¥å®˜æƒ…å ±ãªã—")
            
            # --- é¢æ¥å®Ÿæ–½ ---
            # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æƒ…å ±ã‚’è¡¨ç¤º
            if stage in scheduled_interviews:
                schedule_info = scheduled_interviews[stage]
                print(f"äºˆå®šæ—¥æ™‚: {schedule_info['scheduled_slot']['start']} ã€œ {schedule_info['scheduled_slot']['end']}")
                print(f"é¢æ¥å®˜: {schedule_info['interviewer_info']['name']} ({schedule_info['interviewer_info']['role']})")
                print(f"å½¢å¼: {schedule_info['interview_format']}")
                
                # é¢æ¥å®˜ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½¿ç”¨
                interviewer = SimulatedInterviewer(info=schedule_info['interviewer_info'])
            else:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                interviewer = SimulatedInterviewer(info=current_interviewer_info or {})
            
            question = await interviewer.generate_question(job_list[0], stage=stage, seeker_profile=seeker_profile, resume=resume)
            print("ã€é¢æ¥è³ªå•ã€‘")
            print(question)
            log_json(step_title(f"{stage} è³ªå•"), question)
            log_md(step_title(f"{stage} è³ªå•"), question)
            log_html(step_title(f"{stage} è³ªå•"), question)

            answer = await simulated_seeker.answer_interview(question, seeker_profile=seeker_profile)
            print("ã€é¢æ¥å›ç­”ã€‘")
            print(answer)
            log_json(step_title(f"{stage} å›ç­”"), answer)
            log_md(step_title(f"{stage} å›ç­”"), answer)
            log_html(step_title(f"{stage} å›ç­”"), answer)

            # é¢æ¥çµæœã‚’è¨˜éŒ²ï¼ˆè©•ä¾¡ã¯æŒ¯ã‚Šè¿”ã‚Šä¼šè­°ã§è¡Œã†ï¼‰
            interview_results.append({
                "stage": stage,
                "question": question,
                "answer": answer,
                "schedule_info": scheduled_interviews.get(stage)
            })
            
            # --- ä¼æ¥­å´æŒ¯ã‚Šè¿”ã‚Šä¼šè­°ï¼ˆä¼šè©±å½¢å¼ï¼‰ ---
            step = step_title(f"{stage}å¾Œãƒ»ä¼æ¥­å´æŒ¯ã‚Šè¿”ã‚Šä¼šè­°")
            
            # æŒ¯ã‚Šè¿”ã‚Šä¼šè­°ã‚’ä¼šè©±å½¢å¼ã§ç”Ÿæˆ
            reflection_prompt = f"""
ã‚ãªãŸã¯ä¼æ¥­ã®æ¡ç”¨ãƒãƒ¼ãƒ ã®æŒ¯ã‚Šè¿”ã‚Šä¼šè­°ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã—ã¦ãã ã•ã„ã€‚{stage}ãŒçµ‚äº†ã—ã€3äººã®æ‹…å½“è€…ãŒè­°è«–ã—ã¾ã™ã€‚

ã€é¢æ¥æƒ…å ±ã€‘
- æ®µéš: {stage}
- é¢æ¥è³ªå•: {question}
- æ±‚è·è€…å›ç­”: {answer}

ã€å‚åŠ è€…ã€‘
- ğŸ‘¨â€ğŸ’¼ HRï¼ˆä½è—¤ï¼‰: æ¡ç”¨å…¨ä½“ã‚’ä¿¯ç°ã—ã€ä¼šç¤¾ã®ãƒ‹ãƒ¼ã‚ºã¨ãƒãƒƒãƒã™ã‚‹ã‹ã‚’åˆ¤æ–­ã™ã‚‹äººäº‹æ‹…å½“
- ğŸ‘©â€ğŸ’» é¢æ¥å®˜ï¼ˆç”°ä¸­ï¼‰: æŠ€è¡“é¢ãƒ»äººç‰©é¢ã§ã®ç›´æ¥è©•ä¾¡ã‚’æä¾›ã™ã‚‹ç¾å ´ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼  
- ğŸ¤– empai: ãƒ‡ãƒ¼ã‚¿åˆ†æçš„è¦³ç‚¹ã‹ã‚‰å®¢è¦³çš„åˆ¤æ–­ã‚’æä¾›ã™ã‚‹AIæ¡ç”¨æ”¯æ´ã‚·ã‚¹ãƒ†ãƒ 

ã€ã“ã‚Œã¾ã§ã®é¸è€ƒçµŒéã€‘
- æ›¸é¡é¸è€ƒ: åˆæ ¼
- ä»Šå›ã®é¢æ¥: {stage}

æ¬¡ã®æ®µéšã¯ã€Œ{"ã‚ªãƒ•ã‚¡ãƒ¼æ¤œè¨" if i == len(interview_stages)-1 else interview_stages[i+1]}ã€ã§ã™ã€‚

å®Ÿéš›ã®ä¼šè­°ã®ã‚ˆã†ã«ã€3è€…ãŒè‡ªç„¶ã«è­°è«–ã—ã€æœ€çµ‚çš„ã«æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã®åˆ¤å®šï¼ˆé€²ã‚€/è¦‹é€ã‚Šï¼‰ã‚’æ±ºå®šã—ã¦ãã ã•ã„ã€‚
ä¼šè©±ã¯ä»¥ä¸‹ã®å½¢å¼ã§ï¼š

ğŸ‘¨â€ğŸ’¼ HRï¼ˆä½è—¤ï¼‰: [ç™ºè¨€å†…å®¹]
ğŸ‘©â€ğŸ’» é¢æ¥å®˜ï¼ˆç”°ä¸­ï¼‰: [ç™ºè¨€å†…å®¹]
ğŸ¤– empai: [ç™ºè¨€å†…å®¹]
ğŸ‘¨â€ğŸ’¼ HRï¼ˆä½è—¤ï¼‰: [ç™ºè¨€å†…å®¹]
...

æœ€å¾Œã«æ˜ç¢ºãªçµè«–ã‚’ç¤ºã—ã¦ãã ã•ã„ã€‚

å‡ºåŠ›ã¯å¿…ãšæ—¥æœ¬èªã®ã¿ã§è¡Œã£ã¦ãã ã•ã„ã€‚
"""
            
            reflection_result = await seeker_agent.llm.generate_content_async(
                reflection_prompt,
                agent_name=f"{stage}å¾ŒæŒ¯ã‚Šè¿”ã‚Šä¼šè­°",
                progress_callback=update_progress
            )
            
            print(f"\nã€{stage}å¾Œãƒ»ä¼æ¥­å´æŒ¯ã‚Šè¿”ã‚Šä¼šè­°ã€‘")
            print(reflection_result)
            log_json(step, reflection_result)
            log_md(step, reflection_result)
            log_html(step, reflection_result)
            
            # ä¼æ¥­å´åˆ¤å®šçµæœã‚’æŠ½å‡º
            if any(keyword in reflection_result for keyword in ["è¦‹é€ã‚Š", "ä¸åˆæ ¼", "æ¬¡ã«é€²ã¾ãªã„", "ãŠæ–­ã‚Š", "è¾é€€"]):
                company_decision = "è¦‹é€ã‚Š"
                print(f"\nã€{stage}ãƒ»ä¼æ¥­åˆ¤å®šã€‘è¦‹é€ã‚Š")
                print(f"{stage}ã§ä¼æ¥­å´ãŒè¦‹é€ã‚Šã®ãŸã‚ã€é¸è€ƒã‚’çµ‚äº†ã—ã¾ã™ã€‚")
                log_json(step_title(f"{stage} ä¼æ¥­åˆ¤å®š"), {"result": "è¦‹é€ã‚Š", "reason": "ä¼æ¥­å´æŒ¯ã‚Šè¿”ã‚Šä¼šè­°ã§ã®åˆ¤æ–­"})
                log_md(step_title(f"{stage} ä¼æ¥­åˆ¤å®š"), "è¦‹é€ã‚Š")
                log_html(step_title(f"{stage} ä¼æ¥­åˆ¤å®š"), "è¦‹é€ã‚Š")
                update_realtime_html(is_completed=True)  # å®Œäº†çŠ¶æ…‹ã«æ›´æ–°
                generate_html_file()  # HTMLç”Ÿæˆ
                return
            else:
                company_decision = "é€²ã‚€"
                next_step = interview_stages[i+1] if i < len(interview_stages)-1 else "ã‚ªãƒ•ã‚¡ãƒ¼æ®µéš"
                print(f"\nã€{stage}ãƒ»ä¼æ¥­åˆ¤å®šã€‘{next_step}ã«é€²ã‚€")
                log_json(step_title(f"{stage} ä¼æ¥­åˆ¤å®š"), {"result": company_decision, "next_step": next_step})
                log_md(step_title(f"{stage} ä¼æ¥­åˆ¤å®š"), f"{next_step}ã«é€²ã‚€")
                log_html(step_title(f"{stage} ä¼æ¥­åˆ¤å®š"), f"{next_step}ã«é€²ã‚€")
            
            # --- æ±‚è·è€…å´æŒ¯ã‚Šè¿”ã‚Šä¼šè­°ï¼ˆæ–°æ©Ÿèƒ½ï¼‰ ---
            step = step_title(f"{stage}å¾Œãƒ»æ±‚è·è€…å´æŒ¯ã‚Šè¿”ã‚Šä¼šè­°")
            
            # æ±‚è·è€…å´æŒ¯ã‚Šè¿”ã‚Šä¼šè­°ã‚’ä¼šè©±å½¢å¼ã§ç”Ÿæˆ
            seeker_reflection_prompt = f"""
ã‚ãªãŸã¯è»¢è·æ´»å‹•ä¸­ã®æ±‚è·è€…ã¨ãã®è»¢è·ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æŒ¯ã‚Šè¿”ã‚Šä¼šè­°ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã—ã¦ãã ã•ã„ã€‚{stage}ãŒçµ‚äº†ã—ã€2äººã§é¢æ¥ã®å°è±¡ã‚’è­°è«–ã—ã¾ã™ã€‚

ã€é¢æ¥æƒ…å ±ã€‘
- æ®µéš: {stage}
- é¢æ¥è³ªå•: {question}
- æ±‚è·è€…å›ç­”: {answer}
- ä¼æ¥­å´åˆ¤å®š: {company_decision}

ã€å‚åŠ è€…ã€‘
- ğŸ‘¤ seekerï¼ˆå±±ç”°å¤ªéƒï¼‰: æ±‚è·è€…æœ¬äººã®æ„Ÿæƒ…ã€å°è±¡ã€ä¸å®‰ã€ç›´æ„Ÿã‚’è¡¨ç¾
- ğŸ¯ seekerAIï¼ˆè»¢è·ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼‰: å®¢è¦³çš„ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã€ã‚­ãƒ£ãƒªã‚¢è¦–ç‚¹ã€å¸‚å ´åˆ†æã‚’æä¾›

ã€æ¤œè¨ãƒã‚¤ãƒ³ãƒˆã€‘
- é¢æ¥ä½“é¨“ï¼ˆé¢æ¥å®˜ã®å¯¾å¿œã€è³ªå•ã®è³ªã€é›°å›²æ°—ï¼‰
- ä¼æ¥­æ–‡åŒ–ï¼ˆä¾¡å€¤è¦³ã®ä¸€è‡´ã€åƒãæ–¹ã€ãƒãƒ¼ãƒ ã®å°è±¡ï¼‰  
- ã‚­ãƒ£ãƒªã‚¢å½±éŸ¿ï¼ˆæˆé•·æ©Ÿä¼šã€ã‚¹ã‚­ãƒ«å‘ä¸Šã€å°†æ¥æ€§ï¼‰
- ç›´æ„Ÿãƒ»æ„Ÿæƒ…ï¼ˆãªã‚“ã¨ãªãã®å°è±¡ã€é•å’Œæ„Ÿã€ãƒ¯ã‚¯ãƒ¯ã‚¯æ„Ÿï¼‰

å®Ÿéš›ã®é¢æ¥å¾Œã®ä¼šè©±ã®ã‚ˆã†ã«ã€æ±‚è·è€…ã®ç‡ç›´ãªæ„Ÿæƒ³ã¨è»¢è·ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’è‡ªç„¶ã«è¡¨ç¾ã—ã¦ãã ã•ã„ã€‚
æœ€çµ‚çš„ã«ã€Œç¶™ç¶šã—ãŸã„/æ¡ä»¶ä»˜ãç¶™ç¶š/è¾é€€ã—ãŸã„ã€ã®ã„ãšã‚Œã‹ã®åˆ¤å®šã‚’ç¤ºã—ã¦ãã ã•ã„ã€‚

ä¼šè©±ã¯ä»¥ä¸‹ã®å½¢å¼ã§ï¼š

ğŸ‘¤ seeker: [ç™ºè¨€å†…å®¹]
ğŸ¯ seekerAI: [ç™ºè¨€å†…å®¹]
ğŸ‘¤ seeker: [ç™ºè¨€å†…å®¹]
ğŸ¯ seekerAI: [ç™ºè¨€å†…å®¹]
...

æœ€å¾Œã«æ˜ç¢ºãªç¶™ç¶šæ„æ€ã‚’ç¤ºã—ã¦ãã ã•ã„ã€‚

å‡ºåŠ›ã¯å¿…ãšæ—¥æœ¬èªã®ã¿ã§è¡Œã£ã¦ãã ã•ã„ã€‚
"""
            
            seeker_reflection_result = await seeker_agent.llm.generate_content_async(
                seeker_reflection_prompt,
                agent_name=f"{stage}å¾Œæ±‚è·è€…æŒ¯ã‚Šè¿”ã‚Š",
                progress_callback=update_progress
            )
            
            print(f"\nã€{stage}å¾Œãƒ»æ±‚è·è€…å´æŒ¯ã‚Šè¿”ã‚Šä¼šè­°ã€‘")
            print(seeker_reflection_result)
            log_json(step, seeker_reflection_result)
            log_md(step, seeker_reflection_result)
            log_html(step, seeker_reflection_result)
            
            # æ±‚è·è€…å´åˆ¤å®šçµæœã‚’LLMã§åˆ†æ
            seeker_decision_prompt = f"""
ä»¥ä¸‹ã®æ±‚è·è€…å´æŒ¯ã‚Šè¿”ã‚Šä¼šè­°ã®å†…å®¹ã‚’åˆ†æã—ã€æ±‚è·è€…ãŒé¸è€ƒã‚’ã€Œç¶™ç¶šã—ãŸã„ã€ã‹ã€Œè¾é€€ã—ãŸã„ã€ã‹ã‚’åˆ¤å®šã—ã¦ãã ã•ã„ã€‚

ã€æŒ¯ã‚Šè¿”ã‚Šä¼šè­°ã®å†…å®¹ã€‘
{seeker_reflection_result}

ã€åˆ¤å®šåŸºæº–ã€‘
- ã€Œç¶™ç¶šã—ãŸã„ã€ã€Œæ¡ä»¶ä»˜ãç¶™ç¶šã€ã€Œé€²ã¿ãŸã„ã€ãªã©ã®è¡¨ç¾ãŒã‚ã‚‹å ´åˆã¯ã€Œç¶™ç¶šã€
- ã€Œè¾é€€ã—ãŸã„ã€ã€Œã‚„ã‚ãŸã„ã€ã€Œåˆã‚ãªã„ã€ã€Œç¶™ç¶šã—ãªã„ã€ãªã©ã®è¡¨ç¾ãŒã‚ã‚‹å ´åˆã¯ã€Œè¾é€€ã€
- è¿·ã„ã‚„ä¸å®‰ãŒã‚ã£ã¦ã‚‚ã€æœ€çµ‚çš„ã«å‰å‘ããªæ„æ€ãŒç¤ºã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ã€Œç¶™ç¶šã€
- æ˜ç¢ºãªåˆ¤å®šè¡¨ç¾ãŒãªã„å ´åˆã€å…¨ä½“çš„ãªæ–‡è„ˆã‹ã‚‰åˆ¤æ–­

ä»¥ä¸‹ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§å›ç­”ã—ã¦ãã ã•ã„ï¼š
åˆ¤å®š: ç¶™ç¶š ã¾ãŸã¯ è¾é€€
ç†ç”±: [åˆ¤å®šç†ç”±ã‚’1-2æ–‡ã§]

å¿…ãšæ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚
"""
            
            seeker_decision_result = await seeker_agent.llm.generate_content_async(
                seeker_decision_prompt,
                agent_name=f"{stage}æ±‚è·è€…åˆ¤å®šåˆ†æ",
                progress_callback=update_progress
            )
            
            print(f"\nã€{stage}ãƒ»æ±‚è·è€…åˆ¤å®šåˆ†æã€‘")
            print(seeker_decision_result)
            
            # LLMã®åˆ¤å®šçµæœã‹ã‚‰ã€Œç¶™ç¶šã€ã¾ãŸã¯ã€Œè¾é€€ã€ã‚’æŠ½å‡º
            if "åˆ¤å®š: ç¶™ç¶š" in seeker_decision_result or "åˆ¤å®šï¼šç¶™ç¶š" in seeker_decision_result:
                seeker_decision = "ç¶™ç¶š"
            elif "åˆ¤å®š: è¾é€€" in seeker_decision_result or "åˆ¤å®šï¼šè¾é€€" in seeker_decision_result:
                seeker_decision = "è¾é€€"
            else:
                # LLMã®å›ç­”ã‹ã‚‰åˆ¤å®šã‚’æ¨æ¸¬ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
                if any(keyword in seeker_decision_result for keyword in ["ç¶™ç¶š", "é€²ã‚€", "å‰å‘ã"]):
                    seeker_decision = "ç¶™ç¶š"
                else:
                    seeker_decision = "è¾é€€"
            
            if seeker_decision == "è¾é€€":
                print(f"\nã€{stage}ãƒ»æ±‚è·è€…åˆ¤å®šã€‘è¾é€€")
                print(f"{stage}ã§æ±‚è·è€…ãŒè¾é€€ã®ãŸã‚ã€é¸è€ƒã‚’çµ‚äº†ã—ã¾ã™ã€‚")
                log_json(step_title(f"{stage} æ±‚è·è€…åˆ¤å®š"), {"result": "è¾é€€", "reason": "æ±‚è·è€…å´æŒ¯ã‚Šè¿”ã‚Šä¼šè­°ã§ã®åˆ¤æ–­"})
                log_md(step_title(f"{stage} æ±‚è·è€…åˆ¤å®š"), "è¾é€€")
                log_html(step_title(f"{stage} æ±‚è·è€…åˆ¤å®š"), "è¾é€€")
                update_realtime_html(is_completed=True)  # å®Œäº†çŠ¶æ…‹ã«æ›´æ–°
                generate_html_file()  # HTMLç”Ÿæˆ
                return
            else:
                seeker_decision = "ç¶™ç¶š"
                print(f"\nã€{stage}ãƒ»æ±‚è·è€…åˆ¤å®šã€‘ç¶™ç¶š")
                log_json(step_title(f"{stage} æ±‚è·è€…åˆ¤å®š"), {"result": seeker_decision})
                log_md(step_title(f"{stage} æ±‚è·è€…åˆ¤å®š"), "ç¶™ç¶š")
                log_html(step_title(f"{stage} æ±‚è·è€…åˆ¤å®š"), "ç¶™ç¶š")
            
            # --- æœ€çµ‚åˆ¤å®šï¼ˆä¼æ¥­ãƒ»æ±‚è·è€…ä¸¡æ–¹ã®æ„æ€ç¢ºèªï¼‰ ---
            print(f"\nã€{stage}ãƒ»æœ€çµ‚åˆ¤å®šã€‘ä¼æ¥­:{company_decision} Ã— æ±‚è·è€…:{seeker_decision}")
            if company_decision == "é€²ã‚€" and seeker_decision == "ç¶™ç¶š":
                if i < len(interview_stages)-1:
                    print(f"{next_step}ã«é€²ã¿ã¾ã™ã€‚")
                else:
                    print("å…¨é¢æ¥ã‚’é€šéã—ã¾ã—ãŸã€‚ã‚ªãƒ•ã‚¡ãƒ¼æ®µéšã«é€²ã¿ã¾ã™ã€‚")
            
            log_json(step_title(f"{stage} æœ€çµ‚åˆ¤å®š"), {
                "company_decision": company_decision, 
                "seeker_decision": seeker_decision,
                "result": f"{next_step}ã«é€²ã‚€" if i < len(interview_stages)-1 else "ã‚ªãƒ•ã‚¡ãƒ¼æ®µéšã«é€²ã‚€"
            })
            log_md(step_title(f"{stage} æœ€çµ‚åˆ¤å®š"), f"ä¼æ¥­:{company_decision} Ã— æ±‚è·è€…:{seeker_decision}")
            log_html(step_title(f"{stage} æœ€çµ‚åˆ¤å®š"), f"ä¼æ¥­:{company_decision} Ã— æ±‚è·è€…:{seeker_decision}")

        # --- ã‚ªãƒ•ã‚¡ãƒ¼äº¤æ¸‰ã‚¹ãƒ†ãƒƒãƒ— ---
        # é¢æ¥è©•ä¾¡ãƒªã‚¹ãƒˆã‚’ä½œæˆ
        interview_evaluations = []
        for result in interview_results:
            interview_evaluations.append(result["answer"])
        
        # é¢æ¥è©•ä¾¡ã¨æ±‚è·è€…ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã«åŸºã¥ãå‹•çš„ã‚ªãƒ•ã‚¡ãƒ¼ç”Ÿæˆ
        offer = employer_agent.generate_initial_offer(
            seeker_profile=seeker_profile,
            job=job_list[0],
            interview_evaluations=interview_evaluations
        )
        print("\nã€åˆå›ã‚ªãƒ•ã‚¡ãƒ¼æç¤ºã€‘")
        print(offer)
        log_json(step_title("åˆå›ã‚ªãƒ•ã‚¡ãƒ¼æç¤º"), offer)
        log_md(step_title("åˆå›ã‚ªãƒ•ã‚¡ãƒ¼æç¤º"), offer)
        log_html(step_title("åˆå›ã‚ªãƒ•ã‚¡ãƒ¼æç¤º"), offer)

        max_rounds = 3
        for round_num in range(1, max_rounds + 1):
            print(f"\nã€ã‚ªãƒ•ã‚¡ãƒ¼äº¤æ¸‰ãƒ©ã‚¦ãƒ³ãƒ‰{round_num}ã€‘")
            request = await seeker_agent.request_offer_change(offer)
            print("æ±‚è·è€…ãƒªã‚¯ã‚¨ã‚¹ãƒˆ:", request)
            log_json(step_title(f"äº¤æ¸‰ãƒ©ã‚¦ãƒ³ãƒ‰{round_num} æ±‚è·è€…ãƒªã‚¯ã‚¨ã‚¹ãƒˆ"), request)
            log_md(step_title(f"äº¤æ¸‰ãƒ©ã‚¦ãƒ³ãƒ‰{round_num} æ±‚è·è€…ãƒªã‚¯ã‚¨ã‚¹ãƒˆ"), request)
            log_html(step_title(f"äº¤æ¸‰ãƒ©ã‚¦ãƒ³ãƒ‰{round_num} æ±‚è·è€…ãƒªã‚¯ã‚¨ã‚¹ãƒˆ"), request)
            if request == "ç‰¹ã«ã‚ã‚Šã¾ã›ã‚“":
                print("åˆæ„ã«é”ã—ã¾ã—ãŸã€‚")
                log_json(step_title(f"äº¤æ¸‰ãƒ©ã‚¦ãƒ³ãƒ‰{round_num} åˆæ„"), offer)
                log_md(step_title(f"äº¤æ¸‰ãƒ©ã‚¦ãƒ³ãƒ‰{round_num} åˆæ„"), offer)
                log_html(step_title(f"äº¤æ¸‰ãƒ©ã‚¦ãƒ³ãƒ‰{round_num} åˆæ„"), offer)
                break
            offer = await employer_agent.update_offer(offer, request)
            print("ä¼æ¥­å†æç¤º:", offer)
            log_json(step_title(f"äº¤æ¸‰ãƒ©ã‚¦ãƒ³ãƒ‰{round_num} ä¼æ¥­å†æç¤º"), offer)
            log_md(step_title(f"äº¤æ¸‰ãƒ©ã‚¦ãƒ³ãƒ‰{round_num} ä¼æ¥­å†æç¤º"), offer)
            log_html(step_title(f"äº¤æ¸‰ãƒ©ã‚¦ãƒ³ãƒ‰{round_num} ä¼æ¥­å†æç¤º"), offer)
            if round_num == max_rounds:
                print("æœ€å¤§ãƒ©ã‚¦ãƒ³ãƒ‰ã«é”ã—ãŸãŸã‚ã€ç¾çŠ¶ã‚ªãƒ•ã‚¡ãƒ¼ã§æœ€çµ‚åˆ¤æ–­ã—ã¾ã™ã€‚")
                log_json(step_title(f"äº¤æ¸‰ãƒ©ã‚¦ãƒ³ãƒ‰{round_num} æ‰“ã¡åˆ‡ã‚Š"), offer)
                log_md(step_title(f"äº¤æ¸‰ãƒ©ã‚¦ãƒ³ãƒ‰{round_num} æ‰“ã¡åˆ‡ã‚Š"), offer)
                log_html(step_title(f"äº¤æ¸‰ãƒ©ã‚¦ãƒ³ãƒ‰{round_num} æ‰“ã¡åˆ‡ã‚Š"), offer)

        # --- å—è«¾åˆ¤æ–­ï¼ˆå¯¾è©±å½¢å¼ï¼‰ ---
        step = step_title("ã‚ªãƒ•ã‚¡ãƒ¼å—è«¾åˆ¤æ–­ãƒ—ãƒ­ã‚»ã‚¹")
        offer_decision_result = await simulated_seeker.decide_offer(
            offer=offer,
            seeker_profile=seeker_profile,
            job=job_list[0],
            interview_evaluations=interview_evaluations
        )
        
        # ä¼šè©±ã¨æ±ºæ–­ã‚’è¡¨ç¤º
        print("\nã€ã‚ªãƒ•ã‚¡ãƒ¼å—è«¾åˆ¤æ–­ã®ä¼šè©±ã€‘")
        print(offer_decision_result["conversation"])
        
        # è¿·ã„ã®è©³ç´°æƒ…å ±ã‚’è¡¨ç¤º
        hesitation_score = offer_decision_result.get("hesitation_score", 0)
        hesitation_factors = offer_decision_result.get("hesitation_factors", [])
        decision_confidence = offer_decision_result.get("decision_confidence", 0)
        
        print(f"\nã€è¿·ã„ã®åˆ†æã€‘")
        print(f"è¿·ã„ã‚¹ã‚³ã‚¢: {hesitation_score}")
        if hesitation_factors:
            print("è¿·ã„ã®è¦å› :")
            for factor in hesitation_factors:
                print(f"  - {factor}")
        
        confidence_labels = ["æ¨æ¸¬åˆ¤æ–­", "å‚¾å‘åˆ¤æ–­", "æ˜ç¢ºãªè¡¨ç¾", "æ˜ç¤ºçš„æ±ºæ–­"]
        confidence_text = confidence_labels[min(decision_confidence, 3)]
        print(f"æ±ºæ–­ã®ä¿¡é ¼åº¦: {confidence_text}")
        
        log_json(step, offer_decision_result)
        log_md(step, offer_decision_result["conversation"])
        log_html(step, offer_decision_result["conversation"])
        
        # æœ€çµ‚æ±ºæ–­ã®ã¿åˆ†ã‘ã¦è¡¨ç¤º
        final_decision = "å—è«¾" if offer_decision_result["decision"] else "è¾é€€"
        print(f"\nã€æœ€çµ‚æ±ºæ–­ã€‘{final_decision}")
        log_json(step_title("æœ€çµ‚æ±ºæ–­"), {"decision": final_decision, "confidence": confidence_text, "score": hesitation_score})
        log_md(step_title("æœ€çµ‚æ±ºæ–­"), final_decision)
        log_html(step_title("æœ€çµ‚æ±ºæ–­"), final_decision)
    else:
        print("æ±‚äººã®è©±ã‚’èããŸã„æ„æ€ãŒç¤ºã•ã‚Œãªã‹ã£ãŸãŸã‚ã€ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
        update_realtime_html(is_completed=True)  # å®Œäº†çŠ¶æ…‹ã«æ›´æ–°
        generate_html_file()  # HTMLç”Ÿæˆ
        return

    # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Œäº†å¾Œã€examples/logsã«ã‚µãƒ³ãƒ—ãƒ«ãƒ­ã‚°ã‚’ã‚³ãƒ”ãƒ¼
    print("\nã€ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Œäº†ã€‘")
    print(f"ãƒ­ã‚°ã¯ logs/simulation_log_{now_str}.md ã¨ logs/simulation_log_{now_str}.jsonl ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ")
    
    # HTMLç”Ÿæˆ
    update_realtime_html(is_completed=True)  # å®Œäº†çŠ¶æ…‹ã«æ›´æ–°
    generate_html_file()
    print(f"HTMLå½¢å¼ã®ãƒ­ã‚°ã‚‚ logs/simulation_log_{now_str}.html ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ")
    
    # examples/logsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆã¨ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚³ãƒ”ãƒ¼
    try:
        # examples/logsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
        os.makedirs('examples/logs', exist_ok=True)
        
        # æœ€æ–°ãƒ­ã‚°ã‚’ã‚³ãƒ”ãƒ¼
        shutil.copy(log_md_path, 'examples/logs/latest_simulation.md')
        shutil.copy(log_path, 'examples/logs/latest_simulation.jsonl')
        shutil.copy(log_html_path, 'examples/logs/latest_simulation.html')
        
        print("\nã€ã‚µãƒ³ãƒ—ãƒ«ãƒ­ã‚°ã‚’æ›´æ–°ã€‘")
        print("examples/logs/latest_simulation.md ã¨ examples/logs/latest_simulation.jsonl ã¨ examples/logs/latest_simulation.html ã‚’æ›´æ–°ã—ã¾ã—ãŸ")
        print("â€»ã“ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ­ã‚°ã¯GitHubãƒªãƒã‚¸ãƒˆãƒªã«å«ã¾ã‚Œã¾ã™ã€‚å€‹äººæƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ãªã„ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    except Exception as e:
        print(f"\nã€ã‚µãƒ³ãƒ—ãƒ«ãƒ­ã‚°æ›´æ–°ã‚¨ãƒ©ãƒ¼ã€‘: {e}")
        print("examples/logsã¸ã®ã‚³ãƒ”ãƒ¼ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

if __name__ == "__main__":
    asyncio.run(main()) 